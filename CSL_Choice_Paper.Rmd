---
header-includes: 
  - \thispagestyle{empty}
  - \usepackage{setspace}
  - \setstretch{2}
  - \AtBeginEnvironment{tabular}{\doublespacing}
  - \AtBeginEnvironment{lltable}{\doublespacing}
  - \AtBeginEnvironment{tablenotes}{\doublespacing}
  - \captionsetup[table]{font={stretch=1.5}}
  - \captionsetup[figure]{font={stretch=1.5}}
  - \usepackage{booktabs}

title             : "Selection history guides attention even when top-down control is maximised"
shorttitle        : "Selection history under top-down control"

author: 
  - name          : "Dion T. Henare"
    affiliation   : "1"
    corresponding : yes
    address       : "Gutenbergstraße 18, 35032 Marburg"
    email         : "dion.henare@uni-marburg.de"
  - name          : "Hanna Kadel"
    affiliation   : "1"
  - name          : "Anna Schuboe"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "Philipps-University of Marburg, Germany"

author_note: |
  Funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) – project number 222641018 – SFB/TRR 135 TP B3

abstract: |
  Abstract goes here

bibliography      : ["cslChoice_references.bib"]

figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : no
mask              : no

numbersection     : no
class             : "man"
output            : papaja::apa6_pdf

---

\raggedbottom

```{r setup, include=FALSE}
set.seed(4609948)
library(knitr)
opts_chunk$set(echo = FALSE)

library(tidyr)
library(dplyr)
library(ggplot2)
library(afex)
library(cowplot)
library(papaja)
library(png)
library(grid)
library(emmeans)
#colour, grey, center, categorisation, lateralisation, distractor
```

```{r helperfunctions}
annotation_custom2 <- 
function (grob, xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = Inf, data){ layer(data = data, stat = StatIdentity, position = PositionIdentity, 
        geom = ggplot2:::GeomCustomAnn,
        inherit.aes = TRUE, params = list(grob = grob, 
                                          xmin = xmin, xmax = xmax, 
                                          ymin = ymin, ymax = ymax))}
#Function for making split violin option in ggplot
GeomSplitViolin <- ggproto("GeomSplitViolin", GeomViolin, 
                           draw_group = function(self, data, ..., draw_quantiles = NULL) {
                             data <- transform(data, xminv = x - violinwidth * (x - xmin), xmaxv = x + violinwidth * (xmax - x))
                             grp <- data[1, "group"]
                             newdata <- plyr::arrange(transform(data, x = if (grp %% 2 == 1) xminv else xmaxv), if (grp %% 2 == 1) y else -y)
                             newdata <- rbind(newdata[1, ], newdata, newdata[nrow(newdata), ], newdata[1, ])
                             newdata[c(1, nrow(newdata) - 1, nrow(newdata)), "x"] <- round(newdata[1, "x"])
                             
                             if (length(draw_quantiles) > 0 & !scales::zero_range(range(data$y))) {
                               stopifnot(all(draw_quantiles >= 0), all(draw_quantiles <=
                                                                         1))
                               quantiles <- ggplot2:::create_quantile_segment_frame(data, draw_quantiles)
                               aesthetics <- data[rep(1, nrow(quantiles)), setdiff(names(data), c("x", "y")), drop = FALSE]
                               aesthetics$alpha <- rep(1, nrow(quantiles))
                               both <- cbind(quantiles, aesthetics)
                               quantile_grob <- GeomPath$draw_panel(both, ...)
                               ggplot2:::ggname("geom_split_violin", grid::grobTree(GeomPolygon$draw_panel(newdata, ...), quantile_grob))
                             }
                             else {
                               ggplot2:::ggname("geom_split_violin", GeomPolygon$draw_panel(newdata, ...))
                             }
                           })

geom_split_violin <- function(mapping = NULL, data = NULL, stat = "ydensity", position = "identity", ..., 
                              draw_quantiles = NULL, trim = TRUE, scale = "area", na.rm = FALSE, 
                              show.legend = NA, inherit.aes = TRUE) {
  layer(data = data, mapping = mapping, stat = stat, geom = GeomSplitViolin, 
        position = position, show.legend = show.legend, inherit.aes = inherit.aes, 
        params = list(trim = trim, scale = scale, draw_quantiles = draw_quantiles, na.rm = na.rm, ...))
}

### This script creates an R function to generate raincloud plots, then simulates
### data for plots. If using for your own data, you only need lines 1-80.
### It relies largely on code previously written by David Robinson
### (https://gist.github.com/dgrtwo/eb7750e74997891d7c20)
### and the package ggplot2 by Hadley Wickham

# Check if required packages are installed ----
packages <- c("cowplot", "readr", "ggplot2", "dplyr", "lavaan", "smooth", "Hmisc")
if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
  install.packages(setdiff(packages, rownames(installed.packages())))
}

# Load packages ----
library(ggplot2)

# Defining the geom_flat_violin function ----
# Note: the below code modifies the
# existing github page by removing a parenthesis in line 50

"%||%" <- function(a, b) {
  if (!is.null(a)) a else b
}

geom_flat_violin <- function(mapping = NULL, data = NULL, stat = "ydensity",
                             position = "dodge", trim = TRUE, scale = "area",
                             show.legend = NA, inherit.aes = TRUE, ...) {
  layer(
    data = data,
    mapping = mapping,
    stat = stat,
    geom = GeomFlatViolin,
    position = position,
    show.legend = show.legend,
    inherit.aes = inherit.aes,
    params = list(
      trim = trim,
      scale = scale,
      ...
    )
  )
}

#' @rdname ggplot2-ggproto
#' @format NULL
#' @usage NULL
#' @export
GeomFlatViolin <-
  ggproto("GeomFlatViolin", Geom,
          setup_data = function(data, params) {
            data$width <- data$width %||%
              params$width %||% (resolution(data$x, FALSE) * 0.9)
            
            # ymin, ymax, xmin, and xmax define the bounding rectangle for each group
            data %>%
              group_by(group) %>%
              mutate(
                ymin = min(y),
                ymax = max(y),
                xmin = x,
                xmax = x + width / 2
              )
          },
          
          draw_group = function(data, panel_scales, coord) {
            # Find the points for the line to go all the way around
            data <- transform(data,
                              xminv = x,
                              xmaxv = x + violinwidth * (xmax - x)
            )
            
            # Make sure it's sorted properly to draw the outline
            newdata <- rbind(
              plyr::arrange(transform(data, x = xminv), y),
              plyr::arrange(transform(data, x = xmaxv), -y)
            )
            
            # Close the polygon: set first and last point the same
            # Needed for coord_polar and such
            newdata <- rbind(newdata, newdata[1, ])
            
            ggplot2:::ggname("geom_flat_violin", GeomPolygon$draw_panel(newdata, panel_scales, coord))
          },
          
          draw_key = draw_key_polygon,
          
          default_aes = aes(
            weight = 1, colour = "grey20", fill = "white", size = 0.5,
            alpha = NA, linetype = "solid"
          ),
          
          required_aes = c("x", "y")
  )
```

# Introduction

Everyday visual scenes contain far more information than the human visual system can process at a given point in time. Effective functioning in spite of this limitation requires a system which can flexibly focus its processing on the most relevant parts of a scene. Historically, models of this process have posited that selection is driven by the interaction between bottom-up and top-down influences. Bottom-up processes are based on the physical properties of a stimulus, biasing selection toward things like bright, flashing lights and loud, sudden noises. Top-down processes on the other hand are based on the internal goals of the individual, biasing selection toward, for example, the red and white hat worn by a friend that you’ve lost in a crowd. More recently, @awh2012top suggested that a third factor, selection history, is integrated with both top-down and bottom-up information in order to direct attention in a visual scene.

Selection history refers to an individual’s previous experience of encountering and responding to a stimulus in a given context, and evidence for its impact on attention has come from a range of observations. One such example of how selection history impacts on the deployment of attention is demonstrated by intertrial priming. In visual search tasks where target features vary from trial to trial, intertrial priming refers to the observation that participants respond significantly faster to the current target when it matches the features of the target from the preceding trial [@fecteau2007priming;@nakayama2004short;@maljkovic1994priming;@wolfe2003changing]. Notably, features associated with a previous trial’s target are primed even in cases where they contradict the current top-down goals of the participant [@maljkovic1994priming]. Similarly, associating a stimulus with reward has been shown to produce increased attentional capture by that stimulus long after the reward has stopped [@anderson2011value;@hickey2010reward;@hickey2013reward;@kiss2009reward]. Intertrial priming and reward association both demonstrate the critical role that selection history plays alongside bottom-up and top-down influences on attentional control.

The impact that selection history has on the allocation of attention has also been shown to persist even when participants are performing a different task. @feldmann2015you demonstrated this using a dual task paradigm in which participants performed either a learning task or a search task on each trial. During the learning task participants learned to categorise stimuli based on either colour or shape, while in the search task they searched for a shape singleton and responded to the rotated line that it contained. Their results showed that when colour singletons were present in the search displays, these distractors caused greater interference on the search task for participants who had performed colour categorization in the learning task. This implies that colour became more salient as a result of selection history, and follow-up experiments showed that these effects persist when the tasks are performed in separate blocks, and on separate days.

Additional insight into the effect of learning history on attention has been provided through the measurement of neural indices of attention processing recorded by EEG. One of the predominant components used to study attention is an enhanced negativity recorded at posterior electrode sites contralateral to an attended stimulus, occurring approximately 200ms after stimulus onset. Referred to as N2pc, this component is generally considered to reflect the deployment of spatially selective attention to the stimulus [@ansorge2011initial;@eimer2007attentional;@luck1994spatial;@luck1994electrophysiological], and has been used as an index of attentional capture by relevant stimuli [@kiss2008n2pc] and pop-out objects [@eimer2007attentional;@holguin2009n2pc]. In their dual task investigation into the effects of learning history on attention, @feldmann2015you showed that during search trials, participants that had performed colour categorisation in the learning task produced an N2pc to the colour distractor whereas participants who performed shape categorisation did not. These data support the suggestion that selection history results in the automatic allocation of attention to stimuli even when they are currently task irrelevant.

Recently, methodological developments have allowed for even more specific measures of attention processing using EEG. Efficient attentional orienting depends not only on efficient mechanisms for identifying and orienting to targets, but also the identification and suppression of possible distractors. Distinguishing between these processes using only behavioural measures has proven difficult, however, recent research has identified a set of lateralized event-related potentials that can provide dissociable measures of object selection and suppression. Central to the calculation of the N2pc is the subtraction of any neural activity that is represented equally in both hemispheres. @hickey2009electrophysiological took advantage of this fact in order to dissociate target and distracter processing. Participants in their task performed a visual search task in which both a target and distractor were present, but only one of these objects was lateralized on a given trial. When a target is lateralized and the distractor is on the midline, calculation of lateralized ERPs results in subtraction of all distractor activity and isolation of lateralized target processing. Similarly, when the distractor is lateralized, activity related to distractor processing can be isolated. Results using this approach have identified an early lateralized negativity indexing the attentional selection of a stimulus, and a later lateralized positivity reflecting attentional disengagement from a stimulus.

Specific measures of attentional selection and suppression have provided increased specificity of the role that selection history plays in the orienting of attention. In a follow-up experiment @feldmann2015you adapted their task in order to allow for the dissociation of target and distractor processing. Their results showed that for participants who categorized based on color in the learning task, the presentation of a colored distractor in the search task elicited an ND (a lateralised negativity to distractors) follow by a relatively large PD (a lateralised positivity to distractors). This implies that for these participants, the color distractor captured attention reflexively in the search task (reflected by ND) and therefore required increased subsequent suppression (reflected by increased PD). Participants who had learned to categorize based on shape however did not show this effect. The color distractor in this case elicited no ND during search trials, and a small PD indexing a lack of attentional capture and decreased distractor suppression respectively.

An open question remains as to whether increased top-down control can be used to attenuate, or eliminate the effects of selection history on attention. Previously, dual task investigations of the effect have attempted to enhance top-down control processes by providing cues to participants which inform them of which task they’re about to perform [@kadel2017selection]. While this allows participants to switch task sets in preparation for the upcoming trial, the effect of selection history on attention has remained suggesting that top-down control cannot be used to override the effects of selection history. However, recent work has suggested that these cues are insufficient for allowing participants to optimally engage top-down control before the trial begins. A novel approach to increasing top-down attentional control in dual tasks is the voluntary task-switching paradigm developed by @arrington2004cost. In this version of the task, participants are not cued as to what trial type will be performed next, but rather they are given the choice of which trial type they would like to perform next. Evidence suggests that the voluntary task switching paradigm allows for stronger proactive control over performance of each task [@arrington2005voluntary;kang2014electrophysiological].

In the present study, we adapted the design of @feldmann2015you to a voluntary task switching paradigm in order to investigate the relationship between top-down control and selection history. By allowing participants to determine whether they would perform search or learning on the next trial, participants would be able to proactively engage the task set for the upcoming trial and exercise greater top-down control. We also recorded EEG during their performance of the task and leveraged the procedure of @hickey2009electrophysiological to allow for the isolation of target and distractor activity. This approach provides specific measures of target selection and disengagement, as well as distractor selection and suppression during the task, and therefore provides a fine grained understanding of how increased top-down control interacts with selection history during attentional orienting. If increased top-down control is able to eliminate the effects of selection history then we would expect to see distractor costs in the search task to be similar regardless of whether participants were assigned to the shape or colour group in the learning task. We would als expect that group assignment would have no differential effects on the lateralised ERP components elicited by stimuli in the search task. On the other hand, if top-down control cannot be used to override selection history effects then the effect of learning group assignment on distractor costs and ERP component ampolitudes during search should remain.

# Methods

## Participants

27 participants with normal or corrected-to-normal vision (tested using an Oculus Binoptometer 3) participated in the task for either payment or course credit. All participants gave written and informed consent prior to the start of the experiment. Participants were randomly assigned to either the shape group (ages ranging form XXXX to XXXX, mean = XXXX, SD = XXXX) or the colour group (ages ranging form XXXX to XXXX, mean = XXXX, SD = XXXX). Each group had one left handed participant and all other participants were right handed. One participant did not reach suitable performance during the practice session and was therefore excluded from the experiment.

## Experimental procedure

Participants came in for two separate sessions and performed two different tasks within each session, a learning task and a search task. In session one, participants were familiarised with the two tasks by performing them in separate blocks. In session two, the full task began where participants chose at the start of each trial whether they would perform a learning or search trial. Participants were seated in a comfortable chair in a dimly lit room with their eyes 100cm away from the screen (LCD-TN Samsung Syncmaster 2233). An Erogodex DX1 repsonse pad was placed on their lap with 6 keys arranged so that participants could use the index and middle finger of each hand to respond to the task, while the thumb on each hand could be used to perform task selection between trials. Stimulus presentation and repsonse collection was controlled by E-Prime 2.0 and audio feedback was presented by two stereo speakers (Logitech
Z120 2.0) placed behind the screen.

This procedure followed the logic of @feldmann2015you where selection history is measured as the effect of the learning task on performance in the search task. The addition of voluntary task selection allowed for us to investigate the influence that top-down control may have on the role of selection history.

### Stimuli

All stimuli presented during the learn and search trials were presented on a dark grey background and subtended 2.3 degrees of visual angle. A fixation cross (0.6 degrees) was located in the centre of the screen throughout the experiment in order to help participants maintain central fixation. The physical luminance of the grey, green, blue, and red stimulus colours was balanced using a luminance meter (Konica Minolta LS-100).

### Learning trials

Learning trials began with a 500 ms fixation cross in the center of the screen. Eight stimuli were then presented simultaneously in a circular arrangement for 200 ms, six of these were unfilled grey circles, one was an unfilled coloured circle (either blue or green randomly selected on each trial), and one was an unfilled grey shape singleton (either pentagon or triangle selected randomly on each trial). Participants had two response keys for the learning task and after selecting one of these keys, they were given feedback informing them whether they had selected the correct response. At the beginning of the task, participants were not told the correct stimulus reponse pairing and instead had to learn which key was correct for a given display. For half of the participants (the colour group) the correct response was based on the colour singleton (eg. key 1 when blue was shown, key 2 when green was shown). For the other half of participants (the shape group) the correct response was based on the shape singleton (eg. key 1 when a pentagon was shown, key 2 when a triangle was shown).The trial would end when particpants made their response, up to a maximum of 2000 ms.

### Search trials

Search trials began with a 500 ms fixation cross in the center of the screen. Eight stimuli were then presented simultaneously in a circular arrangement for 200 ms, six of these were always unfilled grey circles, and one was the target, an unfilled grey diamond. The final stimulus was either another unfilled grey circle (in the target only condition) or an unfilled red circle (in the distractor present condition). Each of these stimuli contained a straight line of varying orientations and participants were required to indicate whether the line contained by the target diamond was oriented horizontally or vertically. The trial would end when particpants made their response, up to a maximum of 2000 ms.

### Task selection

In session two, every trial began with a task selection screen where participants had to indicate using either their left or right thumbs, whether they would like to perform a learn or search trial. This screen stayed on until the participant response. Participants were asked to try to ensure that they distributed their choices evenly between the two options, and to try and make their choice random and unpredictable. Participants were required to perform 576 of each trial type and after every block of 32 trials, participants were shown a pictoral display indicating how many of each trial type was left for them to perform as well as some feedback about response times and accuracy (an example is shown in figXXXX). An example of the full trial procedure is shown in figureXXXX.

## EEG recording

EEG activity was recorded continuously at 1000Hz using Brain Products 64 channel actiCAP Ag/AgCl electodes.The electrodes were arranged according to the modified combinatorial nomenclature (MCN) for the 10-10 system. The online reference was FCz and the COM sensor was located on the z axis between FCz and Cz. EEG activity was preamplified by the active electrodes and then passed to a brain products brainamp amplifier with 16 bit A/D conversion, an input impedance of 10MOhms, and an antialiasing filter with a 1000Hz low pass cut off. Impedances were kept below 5kOHms and active shielding was used throughout for attenuating common mode noise.

## EEG processing

EEG data was processed using the EEGLAB toolbox in MATLAB. First, data were segmented into 700ms epochs (-200 to 500ms around each search or learn display) and baselined so that the average of the prestimulus period was set to zero for each event. For artifact rejection a HEOG channel was created by taking the voltage difference between the electrodes on the outer canthi of each eye, and a VEOG was created by taking the voltage difference between the electrodes above and below the left eye. These channels were filtered using a lowpass value of 35Hz in order to reduce false positives, and then trials containing either +/- 35mV in the HEOG channel (within 300ms post stimulus presentation) or +/- 80mV in the VEOG channel were removed. Trials containing +/- 80mv in the channels of interest (PO3, PO7, PO4, and PO8) were also removed and the data were referenced to the average of all channels. Left hemisphere channels (PO3,PO7) were averaged together, and right hemisphere channels (PO4,PO8) were averaged together so that contralateral and ipsilateral ERPs could be calculated for each condition.

## Statistical analysis

### Behavioural analyses

For behavioural analyses we removed any participant whose switch rate for the two tasks was below 0.2, and we removed trials with incorrect responses and abnormally long reaction times (greater than 2.5 standard deviations above the mean, calculated separately for each participant). For analyses where response time is the dependent variable, we also removed trials with incorrect responses. For the categorisation task, independent samples t tests were used to test for differences betweeen participants assigned to the shape group and participants assigned to the colour group. This was performed for both accuracy and response times. For the search task, we used a mixed 2x3 ANOVA where trial type (target only vs target and distractor) was the within-subjects factor, and group (colour vs. shape) was the between-subjects factor. This was performed once with accuracy as the dependent variable and once with repsonse time as the dependent variable. To follow-up the effect of distractor cost we subtracted repsonse times in the target and distractor trials from the target only trial for each participant and ran an independent samples t test to compare distractor cost between the colour and shape group.

### ERP analyses

For the categorisatoin task, participants were excluded if less than 70% of the trials remained in the categorisation task (equivalent to an average of 202 trials remaining in each condition) or if their switch rate between the tasks was less than 0.2. We performed a set of mixed 2x2 ANOVAS where hemisphere (contralateral vs. ipsilateral) was the within-subject factor and group (colour vs. shape) was the between-subject factor.  This was performed with each of the following as the independent variable: NT amplitude in the lateralised shape trials, PD amplitude in the lateralised shape trials, NT amplitude in the lateralise colour trials, and PD amplitude in the lateralised colour trials.

For the search task, trials without a lateralised stimulus were removed, and participants were excluded if less than 85% of trials remained in the search task after artifact rejection (equivalent to an average of 163 trials remaining in each condition) or if their switch rate between the tasks was less than 0.2. We performed a set of mixed 2x2 ANOVAS where hemisphere (contralateral vs. ipsilateral) was the within-subject factor and group (colour vs. shape) was the between-subject factor. This was performed with each of the following as the independent variable: NT amplitude in the target only trials, NT amplitude for the target in the target and distractor trials, ND for the distractor in the target and distractor trials, and PD for the distractor in the target and distractor trials.

# Results
```{r exclusion criteria}
minSwitchRate = 0.2
```

## Behavioral results
```{r loadBehavData}
groupInfo = read.csv(file="BehaviouralData.csv")
#Load all data
behavData = read.csv(file="Behaviour/CSL_Choice_behav.csv")
behavData <- select(behavData,-c(ExperimentName, Session, Clock.Information, DataFile.Basename, Display.RefreshRate, ExperimentVersion, RandomSeed, RuntimeCapabilities, RuntimeVersion, RuntimeVersionExpected, SessionDate, SessionStartDateTimeUtc, SessionTime, StudioVersion,BlockAccC, BlockAccL, BlockRTC, BlockRTL, Group, pos1, pos2, pos3, pos4, pos5, pos6, pos7, pos8, Response.DurationError, Response.OnsetDelay, Response.OnsetTime, Response2.DurationError, Response2.OnsetDelay, Response2.OnsetTime)
)
```

```{r , include=FALSE}

for (sub in unique(behavData$Subject)) {
  behavData$Group[behavData$Subject==sub] = groupInfo$Group[groupInfo$Subject==sub]
  behavData$switchRate[behavData$Subject==sub] = groupInfo$SwitchRate[groupInfo$Subject==sub]
  behavData$compSD[behavData$Subject==sub] = sd(filter(behavData,Subject ==sub, Procedure.Trial. == "TaskC")$CompSearch.RT)
  behavData$compMean[behavData$Subject==sub] = mean(filter(behavData,Subject ==sub, Procedure.Trial. == "TaskC")$CompSearch.RT)
  behavData$learnSD[behavData$Subject==sub] = sd(filter(behavData,Subject ==sub, Procedure.Trial. == "TaskL")$LearnSearch.RT)
  behavData$learnMean[behavData$Subject==sub] = mean(filter(behavData,Subject ==sub, Procedure.Trial. == "TaskL")$LearnSearch.RT)
}
behavData$compCutoff <- behavData$compMean + (behavData$compSD * 2.5)
behavData$learnCutoff <- behavData$learnMean + (behavData$learnSD * 2.5)
behavData <- behavData %>% 
  mutate(SwitchCount = ifelse(repswitch=="switch",1,0))
behavData$Trial <- behavData$Block
behavData$Block <- trunc(unique(behavData$Block)/32-0.00001)+1

#Subject group table
behavData %>% 
  group_by(Subject) %>%
  summarise(Group = mean(Group))
behavData = behavData %>% mutate(Group = ifelse(Group==1,"Colour","Shape"))
behavData$Group = as.factor(behavData$Group)

#Save switch rates for ERP
switchRates <- behavData %>% group_by(Subject) %>%summarise(SR = mean(switchRate))
```

```{r, include = FALSE}
autoCor <- data.frame(matrix(ncol = 3, nrow = 0))
colnames(autoCor) <- c("Cor", "Subject", "Group")

for (subj in unique(behavData$Subject)) {
sData <- behavData %>% filter(Subject == subj)
Cor <- acf(sData$SwitchCount,lag.max = 576,plot = TRUE)$acf
Cor = data.frame(Cor)
Cor$Subject = subj
Cor$Group = behavData$Group[behavData$Subject==subj][1]
autoCor <- rbind(autoCor,Cor[])
}

autoCor$Cor <- sqrt(autoCor$Cor^2)

autoCor %>%
  filter(Cor < 1) %>%
  group_by(Subject,Group) %>%
  summarise(Cor = mean(Cor))
t.test(autoCor$Cor[autoCor$Group=="Colour"],autoCor$Cor[autoCor$Group=="Shape"], paired = FALSE)
```

### Categorisation task

```{r, categorisationStats, include = FALSE}

catAcc <- behavData %>%
  filter(Procedure.Trial. == "TaskL",switchRate>minSwitchRate, LearnSearch.RT < learnCutoff) %>%
  group_by(Subject, Group) %>%
  summarise(Accuracy = mean(LearnSearch.ACC))
t.out = t.test(catAcc$Accuracy[catAcc$Group == "Colour"],catAcc$Accuracy[catAcc$Group == "Shape"])
catAcc.res = apa_print(t.out)

behavData %>%
  filter(Procedure.Trial.== "Task")

catRT <- behavData %>%
  filter(Procedure.Trial. == "TaskL",switchRate>minSwitchRate, LearnSearch.RT < learnCutoff) %>%
  group_by(Subject, Group) %>%
  summarise(RT = mean(LearnSearch.RT))
t.out = t.test(catRT$RT[catRT$Group == "Colour"],catRT$RT[catRT$Group == "Shape"])
catRT.res = apa_print(t.out)
```

In the categorisation task, we see no significant difference between the shape group and the colour group for response times (`r catAcc.res$full_result`) and accuracy (`r catRT.res$full_result`).

### Search task

```{r, SearchStats}
searchAcc <- behavData %>%
  filter(Procedure.Trial. == "TaskC",switchRate>minSwitchRate, CompSearch.RT < compCutoff) %>%
  group_by(Subject, TrialType, Group) %>%
  summarise(Accuracy = mean(CompSearch.ACC))
searchAcc.aov <- aov_ez(
  data = searchAcc,
  dv = "Accuracy",
  id = "Subject", 
  within = c("TrialType"),
  between = "Group"
)
searchAcc.res <- apa_print(searchAcc.aov)

searchRT <- behavData %>%
  filter(Procedure.Trial. == "TaskC",switchRate>minSwitchRate, CompSearch.ACC==1, CompSearch.RT < compCutoff) %>%
  group_by(Subject, TrialType, Group) %>%
  summarise(RT = mean(CompSearch.RT))
searchRT.aov <- aov_ez(
  data = searchRT,
  dv = "RT",
  id = "Subject", 
  within = c("TrialType"),
  between = "Group"
)
searchRT.res <- apa_print(searchRT.aov)
searchRT.fup <- apa_print.emmGrid(pairs(emmeans(searchRT.aov, ~TrialType|Group)))

distCost <- behavData %>%
  filter(Procedure.Trial. == "TaskC",switchRate>minSwitchRate, CompSearch.ACC==1, CompSearch.RT < compCutoff) %>%
  group_by(Subject, TrialType, Group) %>%
  summarise(RT = mean(CompSearch.RT)) %>%
  spread(TrialType, RT) %>%
  mutate(DistInt = TD-Tonly, GroupNum = as.integer(Group))
t.out = t.test(distCost$DistInt[distCost$Group == "Colour"],distCost$DistInt[distCost$Group == "Shape"])
intEffectTTest = apa_print(t.out)
```

Our results failed to detect a significant main effect of group (`r searchAcc.res$full_result$Group`) or trial type (`r searchAcc.res$full_result$TrialType`) on accuracy, and there was no significant interaction between group and trial type (`r searchAcc.res$full_result$Group_TrialType`). We also fail to detect a significant effect of group on response times (`r searchRT.res$full_result$Group`), however we do observe a significant main effect of trial type (`r searchRT.res$full_result$TrialType`), and a significant interaction between group and trial type (`r searchRT.res$full_result$Group_TrialType`). Follow-up tests reveal that participants respond significantly slower when a distractor is present in the search display, and this is true in both the colour group (`r searchRT.fup$full_result$TD_Tonly_Colour`) and the shape group (`r searchRT.fup$full_result$TD_Tonly_Shape`). However, this effect appears to be larger for the colour group and when this is tested directly using an independent samples t-test, the results show that distractor cost is indeed significantly larger for the colour group than the shape group (`r intEffectTTest$full_result`). The effect of group assignment on distractor cost is shown in figure\ \@ref(fig:DistIntViolin).

(ref:behavDistInt) Violin plot showing the response time cost caused by a colored distractor during visual search for both the shape and color trained groups. 

```{r DistIntViolin, fig.cap = "(ref:behavDistInt)"}
behavData %>%
  filter(Procedure.Trial. == "TaskC",switchRate>minSwitchRate, CompSearch.ACC==1, CompSearch.RT < compCutoff) %>%
  group_by(Subject, TrialType, Group) %>%
  summarise(RT = mean(CompSearch.RT)) %>%
  spread(TrialType, RT) %>%
  mutate(DistInt = TD-Tonly, GroupNum = as.integer(Group)) %>%
  ggplot( aes(x = GroupNum, y = DistInt, fill = Group)) +
  geom_flat_violin(aes(fill = Group),position = position_nudge(x = .1, y = 0), adjust = 1.5, trim = FALSE, alpha = .5, colour = NA) +
  geom_point(aes(x = GroupNum-0.15, y = DistInt, colour = Group),position = position_jitter(width = .05), size = 4, shape = 20) +
  geom_boxplot(aes(x = GroupNum, y = DistInt, fill = Group),outlier.shape = NA, alpha = .5, width = .1, colour = "black") +
  scale_color_manual(values=c("green4", "gray42")) +
  scale_fill_manual(values=c("green4", "gray42")) +
  labs(y = "Distractor Cost (ms)") +
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        axis.line = element_line(colour = "black"),
        axis.text.x = element_blank(),
        axis.title.x = element_blank(),
        axis.ticks = element_blank(),
        text= element_text(size=18)
        )
```


```{r, include = FALSE}
rm(behavData, colourBehav, GeomFlatViolin, GeomSplitViolin, groupInfo,intEffectTTest,shapeBehav,t.out, geom_flat_violin,geom_split_violin)
gc()
```

## ERP results

```{r organiseData}
dPath = 'CSL_Visuals/'
fPrefix = 'N2pc'

#Load group data
groupdata = read.csv(file="CSL_Visuals/SophiaGroupAssignment_provisional.csv")
groupdata = groupdata %>% mutate(Group = ifelse(Group == 1, "Colour", "Shape"))
groupdata$Reject = as.factor(groupdata$Reject)

#####
#Creates aggregate of all participant data (needs dPath and fPrefix)
eFilePattern = paste(fPrefix,"*_epochs.csv", sep="")
lFilePattern = paste(fPrefix,"*_LH.csv", sep="")
rFilePattern = paste(fPrefix,"*_RH.csv", sep="")
eFileList = list.files(dPath, pattern=glob2rx(eFilePattern))
lFileList = list.files(dPath, pattern=glob2rx(lFilePattern))
rFileList = list.files(dPath, pattern=glob2rx(rFilePattern))

#create variables using first dataset
epochInfo = read.csv(file = paste(dPath,eFileList[1], sep=""))
epochInfo$Subject = 1
epochInfo$Group = groupdata$Group[1]
epochInfo$Reject = groupdata$Reject[1]
epochInfo$switchRate = switchRates$SR[1]
lHemData = read.csv(file = paste(dPath,lFileList[1], sep=""), header = FALSE)
rHemData = read.csv(file = paste(dPath,rFileList[1], sep=""), header = FALSE)
#append the other datasets to the above variables
for (subj in 2:length(eFileList)) {
  curEpochInfo = read.csv(file = paste(dPath,eFileList[subj], sep=""))
  curEpochInfo$Subject = subj
  curEpochInfo$Group = groupdata$Group[subj]
  curEpochInfo$Reject = groupdata$Reject[subj]
  curEpochInfo$switchRate = switchRates$SR[subj]
  curLHemData = read.csv(file = paste(dPath,lFileList[subj], sep=""), header = FALSE)
  curRHemData = read.csv(file = paste(dPath,rFileList[subj], sep=""), header = FALSE)
  
  epochInfo = rbind(epochInfo, curEpochInfo)
  lHemData = rbind(lHemData, curLHemData)
  rHemData = rbind(rHemData, curRHemData)
}
#Tidy the variables, remove unnecessary and convert to factors
epochInfo$Subject = as.factor(epochInfo$Subject)
epochInfo$Group = as.factor(epochInfo$Group)
epochInfo$VarName8 = NULL
epochInfo$VarName9 = NULL
epochInfo$VarName10 = NULL
epochInfo$VarName11 = NULL

#clear stuff that I don't need
rm(curEpochInfo,curLHemData,curRHemData, fPrefix, eFileList, eFilePattern, lFileList, lFilePattern, rFileList, rFilePattern, subj, groupdata)
#####
#Permutation can be done at this stage using epochInfo$Hemifield = sample(epochInfo$Hemifield, replace=FALSE)
#combine all the data together into one long table
gathercols = colnames(lHemData)
lHemData$Hem = "Left"
rHemData$Hem = "Right"
scalpData = rbind(lHemData,rHemData)
origEpochInfo = rbind(epochInfo,epochInfo)

allData <- cbind(origEpochInfo, scalpData)
allData <- gather(allData, "sample", "voltage", gathercols, factor_key = TRUE)

#Tidy variable names etc. and create any necessary variables - could use unite
allData$sample <- as.integer(substring(allData$sample,2))
allData <- allData %>% mutate(Contra = ifelse(Hemifield==Hem, "Ipsilateral", "Contralateral"))
allData <- allData %>% mutate(Stimulus = as.factor(paste(LatStim," (",MidStim," mid)", sep = "")))
allData <- allData %>% mutate(Object = as.factor(paste(Group,LatStim, sep="")))
allData$Object <- recode(allData$Object, ShapePredictor = "Shape", ColourPredictor="Colour", ShapeNonPred = "Colour", ColourNonPred = "Shape")
allData$Stimulus <- recode(allData$Stimulus, "Target (None mid)" = "Target only", "Target (Distractor mid)"="Target", "Distractor (Target mid)" = "Distractor")

#clear stuff that I don't need
rm(origEpochInfo,scalpData)
#Change factor labels
allData$Object = factor(allData$Object, labels = c("ColourDistractor", "ColourNone", "Lat. Shape", "Lat. Colour", "ColourTarget", "ShapeDistractor", "ShapeNone", "ShapeTarget"))
allData$Object = factor(allData$Object, levels = c("Lat. Colour", "Lat. Shape", "ColourNone", "ShapeNone", "ColourTarget", "ShapeTarget", "ColourDistractor", "ShapeDistractor"))
allData$Group = factor(allData$Group, levels = c("Colour", "Shape"))
allData$TrialType = factor(allData$TrialType, levels = c("Switch", "Rep"))
allData$Stimulus = factor(allData$Stimulus, levels = c("Target only", "Target", "Distractor"))
```

```{r setParams}
baseline = 200
srateMultiplier = 1
plotWidth = 24
plotHeight = 9
fontSize = 12
winSize = 50


learnRej <- allData %>%
  filter(Event == "Learn", sample == 1, Contra == "Contralateral") %>%
  group_by(Subject) %>%
  summarise(Trials = sum(sample)) %>%
  mutate(learnReject = ifelse(Trials < 400,1,0))
searchRej <- allData %>%
  filter(Event == "Search", sample == 1, Contra == "Contralateral") %>%
  group_by(Subject) %>%
  summarise(Trials = sum(sample)) %>%
  mutate(searchReject = ifelse(Trials < 500,1,0))
#mutate(allData, learnRej = NaN, searchRej = NaN)
for (i in unique(allData$Subject)) {
  allData$learnRej[allData$Subject == i] = learnRej$learnReject[learnRej$Subject==i]
  allData$searchRej[allData$Subject == i] = searchRej$searchReject[searchRej$Subject==i]
}
```

### Categorization task

```{r}
grandTarget <- allData %>%
  filter( Event == "Learn" & LatStim == "Predictor" & searchRej == 0) %>%
  mutate(sample = sample*srateMultiplier-baseline) %>%
  filter(sample > 200) %>%
  group_by(sample,Contra) %>%
  summarise(mean = mean(voltage)) %>%
  spread(Contra, mean) %>% 
  mutate(diff = Contralateral - Ipsilateral)
NtStart = grandTarget$sample[grandTarget$diff == min(grandTarget$diff)]-winSize/2
NtEnd = grandTarget$sample[grandTarget$diff == min(grandTarget$diff)]+winSize/2
grandDist <- allData %>%
  filter( Event == "Learn" & LatStim == "NonPred" & searchRej == 0) %>%
  mutate(sample = sample*srateMultiplier-baseline) %>%
  filter(sample > 200) %>%
  group_by(sample,Contra) %>%
  summarise(mean = mean(voltage)) %>%
  spread(Contra, mean) %>% 
  mutate(diff = Contralateral - Ipsilateral)
PdStart = grandDist$sample[grandDist$diff == max(grandDist$diff)]-winSize/2
PdEnd = grandDist$sample[grandDist$diff == max(grandDist$diff)]+winSize/2
```

```{r learnGrand, include = FALSE}
allData %>%
  filter(Event == "Learn", learnRej == 0) %>%
  mutate(sample = sample*srateMultiplier-baseline) %>%
  group_by(LatStim,sample,Contra) %>%
  summarise(mean = mean(voltage)) %>%
  spread(Contra, mean) %>% 
  mutate(diff = Contralateral - Ipsilateral) %>%
  ggplot(., aes(sample,diff)) +
    geom_rect(aes(xmin = NtStart, xmax = NtEnd, ymin = -Inf, ymax = 0), fill = "lemonchiffon") +
    geom_rect(aes(xmin = PdStart, xmax = PdEnd, ymin = 0, ymax = Inf), fill = "lemonchiffon") +
    geom_line(aes(colour = LatStim),size=1) +
    scale_color_manual(values=c("green4", "gray42"))+
    scale_x_continuous(name ="Latency (ms)", expand = c(0, 0)) +
    scale_y_reverse(name =expression(paste("Amplitude (",mu,"v)")), expand = c(0, 0)) +
    geom_vline(xintercept = 0,linetype = "dashed" ) +
    geom_hline(yintercept = 0,linetype = "dashed") +
    theme_apa() +
    theme(panel.spacing.y = unit(3, "lines"), text= element_text(size=fontSize),
          axis.text.x = element_text(size = fontSize*0.93),
          axis.text.y = element_text(size = fontSize*0.93),
          legend.title = element_text( size = fontSize*1.1),
          legend.text = element_text( size = fontSize*0.93),
          legend.position = "bottom"
          )
```

```{r learnStats, echo=FALSE, include = FALSE}
learnNtShape <- allData %>%
  mutate(sample = sample*srateMultiplier-baseline) %>%
  filter(Event == "Learn" & learnRej == 0 & sample>NtStart & sample < NtEnd & Object == "Lat. Shape", switchRate>minSwitchRate) %>%
  group_by(Object,Subject,Contra,Group) %>%
  summarise(mV = mean(voltage))
learn.NtShape.aov <- aov_ez(
  data = learnNtShape,
  dv = "mV",
  id = "Subject", 
  within = c("Contra"),
  between = "Group"
)
learn.NtShape.results <- apa_print(learn.NtShape.aov)
#Followup
learn.NtShape.fup <- apa_print.emmGrid(pairs(emmeans(learn.NtShape.aov, ~Contra|Group)))
diffDirect <- learnNtShape %>%
  spread(Contra,mV) %>%
  mutate(difference = Contralateral-Ipsilateral)
t.test(diffDirect$difference[diffDirect$Group == "Shape"], diffDirect$difference[diffDirect$Group == "Colour"],paired = FALSE)

learnNtCol <- allData %>%
  mutate(sample = sample*srateMultiplier-baseline) %>%
  filter(Event == "Learn" & learnRej == 0 & sample>NtStart & sample < NtEnd & Object == "Lat. Colour", switchRate>minSwitchRate) %>%
  group_by(Object,Subject,Contra,Group) %>%
  summarise(mV = mean(voltage))
learn.NtCol.aov <- aov_ez(
  data = learnNtCol,
  dv = "mV",
  id = "Subject", 
  within = c("Contra"),
  between = "Group"
)
learn.NtCol.results <- apa_print(learn.NtCol.aov)
#Followup
learn.NtCol.fup <- apa_print.emmGrid(pairs(emmeans(learn.NtCol.aov, ~Contra|Group)))
diffDirect <- learnNtCol %>%
  spread(Contra,mV) %>%
  mutate(difference = Contralateral-Ipsilateral)
t.test(diffDirect$difference[diffDirect$Group == "Shape"], diffDirect$difference[diffDirect$Group == "Colour"],paired = FALSE)

learnPdShape <- allData %>%
  mutate(sample = sample*4-baseline) %>%
  filter(Event == "Learn" & learnRej == 0 & sample>PdStart & sample < PdEnd & Object == "Lat. Shape", switchRate>minSwitchRate) %>%
  group_by(Object,Subject,Contra,Group) %>%
  summarise(mV = mean(voltage))
learn.PdShape.aov <- aov_ez(
  data = learnPdShape,
  dv = "mV",
  id = "Subject", 
  within = c("Contra"),
  between = "Group"
)
learn.PdShape.results <- apa_print(learn.PdShape.aov)

learnPdCol <- allData %>%
  mutate(sample = sample*srateMultiplier-baseline) %>%
  filter(Event == "Learn" & learnRej == 0 & sample>PdStart & sample < PdEnd & Object == "Lat. Colour", switchRate>minSwitchRate) %>%
  group_by(Object,Subject,Contra,Group) %>%
  summarise(mV = mean(voltage))
learn.PdCol.aov <- aov_ez(
  data = learnPdCol,
  dv = "mV",
  id = "Subject", 
  within = c("Contra"),
  between = "Group"
)
learn.PdCol.results <- apa_print(learn.PdCol.aov)
```

In the categorisation task, our ERP analyses focused on the lateralised response to each object (either the shape singleton or the colour singleton). For each ERP there were two time windows of interest, the Nt time window (`r sprintf("%i to %ims", NtStart, NtEnd)`) and the Pd time window (`r sprintf("%i to %ims", PdStart, PdEnd)`). See figure\ \@ref(fig:makeLearnPlots).

#### Colour singleton response

When focussing on the lateralised response to a colour singleton we see no significant main effects of either group (`r learn.NtCol.results$full$Group`) or hemisphere (`r learn.NtCol.results$full$Contra`), however we do see a significant interaction between group and hemisphere (`r learn.NtCol.results$full$Group_Contra`). Follow-up comparisons reveal that for participants in the colour group, a lateralised colour singleton elicits a significant NT component (`r learn.NtCol.fup$full_result$Contralateral_Ipsilateral_Colour`), whereas for participants in the shape group a significant lateralised positivity is elicited by the colour singleton (`r learn.NtCol.fup$full_result$Contralateral_Ipsilateral_Shape`). When evaluating the PD time range, we observe no main effects of group(`r learn.PdCol.results$full$Group`) or hemisphere (`r learn.PdCol.results$full$Contra`), and no interaction between group and hemisphere (`r learn.PdCol.results$full$Group_Contra`).

#### Shape singleton response

When focussing on the lateralised response to a shape singleton we again see no significant main effects of either group (`r learn.NtShape.results$full$Group`) or hemisphere (`r learn.NtShape.results$full$Contra`), however we do see a significant interaction between group and hemisphere (`r learn.NtShape.results$full$Group_Contra`). Follow-up comparisons reveal that for participants in the shape group, a lateralised shape singleton elicits a significant NT component (`r learn.NtShape.fup$full_result$Contralateral_Ipsilateral_Shape`), whereas for participants in the colour group a significant lateralised positivity is elicited by the shape singleton (`r learn.NtShape.fup$full_result$Contralateral_Ipsilateral_Colour`).  When evaluating the PD time range, we observe no main effects of group(`r learn.PdShape.results$full$Group`) or hemisphere (`r learn.PdShape.results$full$Contra`), and no interaction between group and hemisphere (`r learn.PdShape.results$full$Group_Contra`).

(ref:learnERPCap) Subtractracted ERPs showing the lateralized response to the shape singleton (top) and color singleton (bottom) for each group in the categorization task. Example displays are shown for each ERP.

```{r makeLearnPlots, fig.cap="(ref:learnERPCap)"}
imgCol <- readPNG("learnCol.png")
imgShape <- readPNG("learnShape.png")
#Subtracted
allData %>%
  filter(Event == "Learn", learnRej == 0) %>%
  mutate(sample = sample*srateMultiplier-baseline) %>%
  group_by(Object,sample,Contra,Group) %>%
  summarise(mean = mean(voltage)) %>%
  spread(Contra, mean) %>% 
  mutate(diff = Contralateral - Ipsilateral) %>%
  ggplot(., aes(sample,diff)) +
    geom_rect(aes(xmin = NtStart, xmax = NtEnd, ymin = -Inf, ymax = 0), fill = "lemonchiffon") +
    geom_rect(aes(xmin = PdStart, xmax = PdEnd, ymin = 0, ymax = Inf), fill = "lemonchiffon") +
    geom_line(aes(colour = Group),size=1) +
    scale_color_manual(values=c("green4", "gray42"))+
    scale_x_continuous(name ="Latency (ms)", expand = c(0, 0)) +
    scale_y_reverse(name =expression(paste("Amplitude (",mu,"v)")), expand = c(0, 0)) +
    coord_cartesian(clip = 'off') +
    geom_vline(xintercept = 0,linetype = "dashed" )+
    geom_hline(yintercept = 0,linetype = "dashed") +
    annotation_custom2(rasterGrob(imgCol, interpolate=TRUE), 
                       xmin=-45, 
                       xmax=45, 
                       ymin=0.25, 
                       ymax=3, 
                       data=. %>% filter(Object  == "Lat. Colour"))+
    annotation_custom2(rasterGrob(imgShape, interpolate=TRUE), 
                       xmin=-45, 
                       xmax=45, 
                       ymin=0.25, 
                       ymax=3, 
                       data=. %>% filter(Object  == "Lat. Shape"))+
    facet_grid(Object~.) +
    theme_apa() +
    theme(panel.spacing.y = unit(3, "lines"), text= element_text(size=fontSize),
          axis.text.x = element_text(size = fontSize*0.93),
          axis.text.y = element_text(size = fontSize*0.93),
          legend.title = element_text( size = fontSize*1.1),
          legend.text = element_text( size = fontSize*0.93),
          legend.position = "bottom",
          plot.margin = unit(c(2,2,0,2),"cm")
          )
ggsave("LearnSubtracted.pdf", dpi = 300, width = 30, height = 20, units = c("cm"))
```

### Search task

```{r}
grandTarget <- allData %>%
  filter( Event == "Search" & LatStim == "Target" & searchRej == 0) %>%
  mutate(sample = sample*srateMultiplier-baseline) %>%
  filter(sample > 200) %>%
  group_by(sample,Contra) %>%
  summarise(mean = mean(voltage)) %>%
  spread(Contra, mean) %>% 
  mutate(diff = Contralateral - Ipsilateral)
NtStart = grandTarget$sample[grandTarget$diff == min(grandTarget$diff)]-winSize/2
NtEnd = grandTarget$sample[grandTarget$diff == min(grandTarget$diff)]+winSize/2
grandDist <- allData %>%
  filter( Event == "Search" & LatStim == "Distractor" & searchRej == 0) %>%
  mutate(sample = sample*srateMultiplier-baseline) %>%
  filter(sample > 200) %>%
  group_by(sample,Contra) %>%
  summarise(mean = mean(voltage)) %>%
  spread(Contra, mean) %>% 
  mutate(diff = Contralateral - Ipsilateral)
PdStart = grandDist$sample[grandDist$diff == max(grandDist$diff)]-winSize/2
PdEnd = grandDist$sample[grandDist$diff == max(grandDist$diff)]+winSize/2
```

```{r searchGrand, include = FALSE}
allData %>%
  filter( Event == "Search" & LatStim != "None" & searchRej == 0) %>%
  mutate(sample = sample*srateMultiplier-baseline) %>%
  group_by(LatStim,sample,Contra) %>%
  summarise(mean = mean(voltage)) %>%
  spread(Contra, mean) %>% 
  mutate(diff = Contralateral - Ipsilateral) %>%
  ggplot(., aes(sample,diff)) +
    geom_rect(aes(xmin = NtStart, xmax = NtEnd, ymin = -Inf, ymax = 0), fill = "lemonchiffon") +
    geom_rect(aes(xmin = PdStart, xmax = PdEnd, ymin = 0, ymax = Inf), fill = "lemonchiffon") +
    geom_line(aes(colour = LatStim),size=1) +
    #scale_color_manual(values=c("green4", "gray42"))+
    scale_x_continuous(name ="Latency (ms)", expand = c(0, 0)) +
    scale_y_reverse(name =expression(paste("Amplitude (",mu,"v)")), expand = c(0, 0)) +
    geom_vline(xintercept = 0,linetype = "dashed" ) +
    geom_hline(yintercept = 0,linetype = "dashed") +
    theme_apa() +
    theme(panel.spacing.y = unit(3, "lines"), text= element_text(size=fontSize),
          axis.text.x = element_text(size = fontSize*0.93),
          axis.text.y = element_text(size = fontSize*0.93),
          legend.title = element_text( size = fontSize*1.1),
          legend.text = element_text( size = fontSize*0.93),
          legend.position = "bottom"
          )
```

```{r searchStatsBasic, echo=FALSE}
searchNtTO <- allData %>%
  mutate(sample = sample*srateMultiplier-baseline) %>%
  filter(Event == "Search" & LatStim != "None" & searchRej == 0 & sample>NtStart & sample < NtEnd & Stimulus == "Target only", switchRate>minSwitchRate) %>%
  group_by(Stimulus,Subject,Contra,Group) %>%
  summarise(mV = mean(voltage)) 
search.NtTO.aov <- aov_ez(
  data = searchNtTO,
  dv = "mV",
  id = "Subject", 
  within = c("Contra"),
  between = "Group"
)
search.NtTO.results <- apa_print(search.NtTO.aov)
search.NtTO.fup <- apa_print.emmGrid(pairs(emmeans(search.NtTO.aov, ~Contra|Group)))

searchNtTD <- allData %>%
  mutate(sample = sample*srateMultiplier-baseline) %>%
  filter(Event == "Search" & LatStim != "None" & searchRej == 0 & sample>NtStart & sample < NtEnd & Stimulus == "Target", switchRate>minSwitchRate) %>%
  group_by(Stimulus,Subject,Contra,Group) %>%
  summarise(mV = mean(voltage))
search.NtTD.aov <- aov_ez(
  data = searchNtTD,
  dv = "mV",
  id = "Subject", 
  within = c("Contra"),
  between = "Group"
)
search.NtTD.results <- apa_print(search.NtTD.aov)
search.NtTD.fup <- apa_print.emmGrid(pairs(emmeans(search.NtTD.aov, ~Contra|Group)))
diffDirect <- searchNtTD %>%
  spread(Contra,mV) %>%
  mutate(difference = Contralateral-Ipsilateral)
NtTDdiff <- apa_print(t.test(diffDirect$Contralateral[diffDirect$Group == "Shape"], diffDirect$Ipsilateral[diffDirect$Group == "Shape"],paired = TRUE))

searchNtDT <- allData %>%
  mutate(sample = sample*srateMultiplier-baseline) %>%
  filter(Event == "Search" & LatStim != "None" & searchRej == 0 & sample>NtStart & sample < NtEnd & Stimulus == "Distractor", switchRate>minSwitchRate) %>%
  group_by(Stimulus,Subject,Contra,Group) %>%
  summarise(mV = mean(voltage))
search.NtDT.aov <- aov_ez(
  data = searchNtDT,
  dv = "mV",
  id = "Subject", 
  within = c("Contra"),
  between = "Group"
)
search.NtDT.results <- apa_print(search.NtDT.aov)
search.NtDT.fup <- apa_print.emmGrid(pairs(emmeans(search.NtDT.aov, ~Contra|Group)))

searchPdDT <- allData %>%
  mutate(sample = sample*srateMultiplier-baseline) %>%
  filter( Event == "Search" & LatStim != "None" & searchRej == 0 & sample>PdStart & sample < PdEnd & Stimulus == "Distractor", switchRate>minSwitchRate) %>%
  group_by(Stimulus,Subject,Contra,Group) %>%
  summarise(mV = mean(voltage))
search.PdDT.aov <- aov_ez(
  data = searchPdDT,
  dv = "mV",
  id = "Subject", 
  within = c("Contra"),
  between = "Group"
)
search.PdDT.results <- apa_print(search.PdDT.aov)
search.PdDT.fup <- apa_print.emmGrid(pairs(emmeans(search.PdDT.aov, ~Contra|Group)))
diffDirect <- searchPdDT %>%
  spread(Contra,mV) %>%
  mutate(difference = Contralateral-Ipsilateral)
PdDTdiff <- apa_print(t.test(diffDirect$difference[diffDirect$Group == "Colour"], diffDirect$difference[diffDirect$Group == "Shape"],paired = FALSE))

```

Next we focused on the lateralised response to stimuli in the search displays as a function of group assignment. Evidence for the effect of selection history would again come from the interaction between group and lateralised ERP activity.

#### Target response - Distractor absent trials

In the target only displays there was a significant main effect of hemisphere where the contralateral response is more negative than the ipsilateral response (`r search.NtTO.results$full$Contra`), but no siginificant main effect of group (`r search.NtTO.results$full$Group`), and no interaction between group and hemisphere (`r search.NtTO.results$full$Group_Contra`).

#### Target response - Distractor present trials

Results for the lateralised target in the presence of a distractor showed no significant main effect of group (`r search.NtTD.results$full$Group`), however there was a significant main effect of hemisphere (`r search.NtTD.results$full$Contra`), as well as a significant interaction between group and hemisphere (`r search.NtTD.results$full$Group_Contra`). Follow-up comparisons reveal that a significant NT was elicited for participants in both the colour (`r search.NtTD.fup$full_result$Contralateral_Ipsilateral_Colour`) and shape group (`r search.NtTD.fup$full_result$Contralateral_Ipsilateral_Colour`). When NT amplitude is compared directly with an independent samples t test, the results show that the NT is significantly larger for the shape group than the colour group (`r NtTDdiff$full_result`).

#### Distractor response

Results for the lateralised distractor showed no significant main effect of group (`r search.PdDT.results$full$Group`), however there was a significant main effect of hemisphere (`r search.PdDT.results$full$Contra`), as well as a significant interaction between group and hemisphere (`r search.PdDT.results$full$Group_Contra`). Follow-up comparisons reveal that a significant Pd was elicited for participants in the colour group (`r search.PdDT.fup$full_result$Contralateral_Ipsilateral_Colour`), however there was no significant difference between the contralateral and ipsilateral electrodes for the shape group (`r search.PdDT.fup$full_result$Contralateral_Ipsilateral_Shape`). When Pd amplitude is compared directly with an independent samples t test, the results show that the Pd is significantly larger for the colour group than the shape group (`r PdDTdiff$full_result`).

(ref:searchERPCap) Subtractracted ERPs showing the lateralized response to a target in the absence of distractors (top, the target in the presence of a distractor (middle), and the distractor (bottom) for each group in the search task. Example displays are shown for each ERP.

```{r makeSearchPlots, fig.cap="(ref:searchERPCap)", fig.height = 5.25,  fig.align = "center"}

imgTO = readPNG("searchTO.png")
imgTD = readPNG("searchTD.png")
imgDT = readPNG("searchDT.png")
allData %>%
  filter( Event == "Search" & LatStim != "None" & searchRej == 0) %>%
  mutate(sample = sample*srateMultiplier-baseline) %>%
  group_by(Stimulus,sample,Contra,Group) %>%
  summarise(mean = mean(voltage)) %>%
  spread(Contra, mean) %>% 
  mutate(diff = Contralateral - Ipsilateral) %>%
  ggplot(., aes(sample,diff)) +
    geom_rect(aes(xmin = NtStart, xmax = NtEnd, ymin = -Inf, ymax = 0), fill = "lemonchiffon") +
    geom_rect(data = . %>% filter(Stimulus  == "Distractor"),aes(xmin = PdStart, xmax = PdEnd, ymin = 0, ymax = Inf), fill = "lemonchiffon") +
    geom_line(aes(colour = Group),size=1) +
    scale_color_manual(values=c("green4", "gray42"))+
    #scale_colour_brewer(palette = "Set1") +
    scale_x_continuous(name ="Latency (ms)", expand = c(0, 0)) +
    scale_y_reverse(name =expression(paste("Amplitude (",mu,"v)")), expand = c(0, 0)) +
    coord_cartesian(clip = 'off') +
    geom_vline(xintercept = 0,linetype = "dashed" )+
    geom_hline(yintercept = 0,linetype = "dashed") +
    annotation_custom2(rasterGrob(imgTO, interpolate=TRUE), 
                       xmin=-45, 
                       xmax=45, 
                       ymin=0.5, 
                       ymax=3.2, 
                       data=. %>% filter(Stimulus  == "Target only"))+
    annotation_custom2(rasterGrob(imgTD, interpolate=TRUE), 
                       xmin=-45, 
                       xmax=45, 
                       ymin=0.5, 
                       ymax=3.2, 
                       data=. %>% filter(Stimulus  == "Target"))+
    annotation_custom2(rasterGrob(imgDT, interpolate=TRUE), 
                       xmin=-45, 
                       xmax=45, 
                       ymin=0.5, 
                       ymax=3.2, 
                       data=. %>% filter(Stimulus  == "Distractor"))+
    facet_grid(Stimulus~.) +
    theme_apa() +
    theme(panel.spacing.y = unit(3, "lines"), text= element_text(size=fontSize),
          axis.text.x = element_text(size = fontSize*0.93),
          axis.text.y = element_text(size = fontSize*0.93),
          legend.title = element_text( size = fontSize*1.1),
          legend.text = element_text( size = fontSize*0.93),
          legend.position = "bottom",
          plot.margin = unit(c(2,2,0,2),"cm")
          )
ggsave("SearchSubtracted.pdf", dpi = 300, width = 30, height = 40, units = c("cm"))
```

# Discussion

Previous research has established that an individual's learning history biases their attention during visual search, even when that learning history is task irrelevant and impairs search performance. In this study, we aimed to test whether the effects of learning history on attention guidance can be eliminated in situations where top-down control is maximised. To this end, we used a voluntary task selection design which allowed participants to decide which task they would like to perform on each trial. The results showed that learning history continues to bias attention during visual search leading to impaired target selection and distractor suppression. These effects are reflected both in response times as increased distractor costs, and in lateralised ERP components as simultaneous attenuation of the NT component and increase of the PD component.

This pattern of results is consistent with the results of @feldmann2015you who used a version of this task which allowed for only limited top-down control. In their experiment, participants were also randomly assigned to either a colour learning, or shape learning group and asked to perform two tasks. In the ategorisation task their responses depended on group assignment (categorising either the colour or shape singleton) and in the search task all participants had to search for and respond to a line within a shape singleton. In their version of the task, the two tasks were randomly intermixed and participants had no way of knowing whether the upcoming trial would be a categorisation trial or a search trial. Their results showed that colour categorisers incurred greater response time costs when a colour distractor was present in the search display relative to shape categorisers. The ERP results in their task for the most part align with ours. When search targets are presented alone, there is no difference in the NT amplitude for the two groups. However, when colour distractors are present, the NT to targets is larger in the shape group implying improved target selection, and the PD to distractors is larger in the colour group implying an increased need for distractor suppression. The fact that this pattern of results persists when voluntary task selection is used in our case, suggests that selection history is the result of an implicit accrual of __ and that it biases attention automatically.

One difference observed between the results of @feldmann2015you and our study is that they observed a negativity to distractors in the search task for participants in the colour group whereas we see no such component. A negativity to distractors, sometimes referred to as the ND, has been observed in a number of search tasks and is typically viewed as reflecting attentional selection of the distractor and therefore analogous to the NT. @feldmann2015you suggested that an ND was elicited for the colour group in response to colour distractors because their selection history in the categorisation task causes the coloured distractor to capture attention in the search task. The fact that we see no evidence of this capture in our task may suggest that the increased top-down control granted by voluntary selection allows participants to prevent this iniial capture by colour distractors. An implication of our results may therefore be that top-down control can be used to prevent initial capture of distractors, but that this in itself does not prevent the need for some distractor suppression (as indexed by the large PD).

These results confirm and extend previous attempts to understand how selection history's effects persist under a range of contexts. In their study, @kadel2017selection used the same dual task paradigm employed here in which participants categorise either shapes or colours on one task, and then search for a shape singleton in the second task. Across three experiments @kadel2017selection used variations in which the participants were cued about the task they would perform on the subsequent trial, performed the tasks in a fixed order, as well as performing the tasks on separate days across two sessions. In all cases @kadel2017selection observed the same selection history effects reported here. Distractor costs in the search task were larger for the colour group in each experiment, and ERP results suggested that participants in the shape group were better able to focus their attention on the shape target in the presence of a colour distractor, whereas those in the colour group were relatively impaired in their ability to select the shape target when a colour distractor was present. These results support the suggestion that top-down preparation cannot overrule the effect that selection history has on attentional filter settings.

Our study extends on these results in two main ways. Firstly our experiemnt used a voluntary task selection paradigm which has been shown to allow for increased top-down control relative to other procedures in the task switching literature. Secondly, the stimulus displays in our task are arranged in a way which allows for the dissociation of target and distractor responses in the EEG data.

One notable feature of the ERP in our tasks is the wide shallow nature of the lateralised positivity during the categorisation task, particularly in the case of a lateralised colour singleton. Whereas the lateralised responses evoked in the search task reflect the features of typical NT/PD components, the lateralised response in the categorisation task showed significant overlap in the time ranges of the NT and PD, and a broadly distributed positivty in the case of lateralised colour singletons. We also observe a possible lateralised positivty to the target stimulus (colour singleton for the colour group, and shape singleton for the shape group) which follows the initial NT response.

The observation that top-down control can not be used to eliminate the effects of selection history is consistent with the suggestion that selection history operates reflexively

Our results suggest that learning history operates implicitly and automatically when 

These effects extend on the findings of @kadel2017selection who also attempted to demonstrate the resilience of learning history to top-down control mechanisms. 

Learning history acts implicitly

```{r, previousExamplesOfSelectionHistoryAndPostulatedMechanisms}
#Several studies showed that when specific stimulus features or dimensions are reliable
#predictors of an outcome, they induce an attentional bias in favor of these stimuli (e.g., Le
#Pelley, Suret, & Beesley, 2009; Le Pelley et al., 2013; Mitchell & Le Pelley, 2010).
#Moreover, stimuli previously shown to be predictive for a specific outcome are more rapidly
#learned about subsequently (learned predictiveness effect; Le Pelley & McLaren, 2003). Both
#deliberate attentional selection as well as automatic attentional capture are influenced by
#learned predictiveness (Le Pelley, Mitchell, Beesley, George, & Wills, 2016). There are two
#explanatory approaches (see Pinto, Vogel, & Núñez, 2017): associative interpretations and
#propositional interpretations. According to the associative approach, a link between
#representations of a stimulus and the representation of an outcome is formed in a relatively
#automatic way and without much cognitive control. In contrast, the propositional approach
#(e.g., Mitchell, De Houwer, & Lovibond, 2009) assumes that predictive learning is based on
#effortful higher-order cognitive processes. Most likely, both associative and propositional
#influences play a role (Pinto et al., 2017). 
```

# References
