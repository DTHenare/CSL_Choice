---
header-includes: 
  - \thispagestyle{empty}
  - \usepackage{setspace}
  - \setstretch{2}
  - \AtBeginEnvironment{tabular}{\doublespacing}
  - \AtBeginEnvironment{lltable}{\doublespacing}
  - \AtBeginEnvironment{tablenotes}{\doublespacing}
  - \captionsetup[table]{font={stretch=1.5}}
  - \captionsetup[figure]{font={stretch=1.5}}
  - \usepackage{booktabs}

title             : "Selection history guides attention even when top-down control is maximised"
shorttitle        : "Selection history under top-down control"

author: 
  - name          : "Dion T. Henare"
    affiliation   : "1"
    corresponding : yes
    address       : "Gutenbergstraße 18, 35032 Marburg"
    email         : "dion.henare@uni-marburg.de"
  - name          : "Hanna Kadel"
    affiliation   : "1"
  - name          : "Anna Schuboe"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "Philipps-University of Marburg, Germany"

author_note: |
  Funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) – project number 222641018 – SFB/TRR 135 TP B3

abstract: |
  Abstract goes here

bibliography      : ["cslChoice_references.bib"]

figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : no
mask              : no

numbersection     : no
class             : "man"
output            : papaja::apa6_pdf

---

\raggedbottom

```{r setup, include=FALSE}
set.seed(4609948)
library(knitr)
opts_chunk$set(echo = FALSE)

library(tidyr)
library(dplyr)
library(ggplot2)
library(afex)
library(cowplot)
library(papaja)
library(png)
library(grid)
library(emmeans)
#colour, grey, center, categorisation, lateralisation, distractor
```

```{r helperfunctions}
annotation_custom2 <- 
function (grob, xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = Inf, data){ layer(data = data, stat = StatIdentity, position = PositionIdentity, 
        geom = ggplot2:::GeomCustomAnn,
        inherit.aes = TRUE, params = list(grob = grob, 
                                          xmin = xmin, xmax = xmax, 
                                          ymin = ymin, ymax = ymax))}
#Function for making split violin option in ggplot
GeomSplitViolin <- ggproto("GeomSplitViolin", GeomViolin, 
                           draw_group = function(self, data, ..., draw_quantiles = NULL) {
                             data <- transform(data, xminv = x - violinwidth * (x - xmin), xmaxv = x + violinwidth * (xmax - x))
                             grp <- data[1, "group"]
                             newdata <- plyr::arrange(transform(data, x = if (grp %% 2 == 1) xminv else xmaxv), if (grp %% 2 == 1) y else -y)
                             newdata <- rbind(newdata[1, ], newdata, newdata[nrow(newdata), ], newdata[1, ])
                             newdata[c(1, nrow(newdata) - 1, nrow(newdata)), "x"] <- round(newdata[1, "x"])
                             
                             if (length(draw_quantiles) > 0 & !scales::zero_range(range(data$y))) {
                               stopifnot(all(draw_quantiles >= 0), all(draw_quantiles <=
                                                                         1))
                               quantiles <- ggplot2:::create_quantile_segment_frame(data, draw_quantiles)
                               aesthetics <- data[rep(1, nrow(quantiles)), setdiff(names(data), c("x", "y")), drop = FALSE]
                               aesthetics$alpha <- rep(1, nrow(quantiles))
                               both <- cbind(quantiles, aesthetics)
                               quantile_grob <- GeomPath$draw_panel(both, ...)
                               ggplot2:::ggname("geom_split_violin", grid::grobTree(GeomPolygon$draw_panel(newdata, ...), quantile_grob))
                             }
                             else {
                               ggplot2:::ggname("geom_split_violin", GeomPolygon$draw_panel(newdata, ...))
                             }
                           })

geom_split_violin <- function(mapping = NULL, data = NULL, stat = "ydensity", position = "identity", ..., 
                              draw_quantiles = NULL, trim = TRUE, scale = "area", na.rm = FALSE, 
                              show.legend = NA, inherit.aes = TRUE) {
  layer(data = data, mapping = mapping, stat = stat, geom = GeomSplitViolin, 
        position = position, show.legend = show.legend, inherit.aes = inherit.aes, 
        params = list(trim = trim, scale = scale, draw_quantiles = draw_quantiles, na.rm = na.rm, ...))
}

### This script creates an R function to generate raincloud plots, then simulates
### data for plots. If using for your own data, you only need lines 1-80.
### It relies largely on code previously written by David Robinson
### (https://gist.github.com/dgrtwo/eb7750e74997891d7c20)
### and the package ggplot2 by Hadley Wickham

# Check if required packages are installed ----
packages <- c("cowplot", "readr", "ggplot2", "dplyr", "lavaan", "smooth", "Hmisc")
if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
  install.packages(setdiff(packages, rownames(installed.packages())))
}

# Load packages ----
library(ggplot2)

# Defining the geom_flat_violin function ----
# Note: the below code modifies the
# existing github page by removing a parenthesis in line 50

"%||%" <- function(a, b) {
  if (!is.null(a)) a else b
}

geom_flat_violin <- function(mapping = NULL, data = NULL, stat = "ydensity",
                             position = "dodge", trim = TRUE, scale = "area",
                             show.legend = NA, inherit.aes = TRUE, ...) {
  layer(
    data = data,
    mapping = mapping,
    stat = stat,
    geom = GeomFlatViolin,
    position = position,
    show.legend = show.legend,
    inherit.aes = inherit.aes,
    params = list(
      trim = trim,
      scale = scale,
      ...
    )
  )
}

#' @rdname ggplot2-ggproto
#' @format NULL
#' @usage NULL
#' @export
GeomFlatViolin <-
  ggproto("GeomFlatViolin", Geom,
          setup_data = function(data, params) {
            data$width <- data$width %||%
              params$width %||% (resolution(data$x, FALSE) * 0.9)
            
            # ymin, ymax, xmin, and xmax define the bounding rectangle for each group
            data %>%
              group_by(group) %>%
              mutate(
                ymin = min(y),
                ymax = max(y),
                xmin = x,
                xmax = x + width / 2
              )
          },
          
          draw_group = function(data, panel_scales, coord) {
            # Find the points for the line to go all the way around
            data <- transform(data,
                              xminv = x,
                              xmaxv = x + violinwidth * (xmax - x)
            )
            
            # Make sure it's sorted properly to draw the outline
            newdata <- rbind(
              plyr::arrange(transform(data, x = xminv), y),
              plyr::arrange(transform(data, x = xmaxv), -y)
            )
            
            # Close the polygon: set first and last point the same
            # Needed for coord_polar and such
            newdata <- rbind(newdata, newdata[1, ])
            
            ggplot2:::ggname("geom_flat_violin", GeomPolygon$draw_panel(newdata, panel_scales, coord))
          },
          
          draw_key = draw_key_polygon,
          
          default_aes = aes(
            weight = 1, colour = "grey20", fill = "white", size = 0.5,
            alpha = NA, linetype = "solid"
          ),
          
          required_aes = c("x", "y")
  )
```

# Introduction

Everyday visual scenes contain far more information than the human visual system can process at a given point in time. Effective functioning in spite of this limitation requires a system which can flexibly focus its processing on the most relevant parts of a scene. Historically, models of this process have posited that selection is driven by the interaction between bottom-up and top-down influences. Bottom-up processes are based on the physical properties of a stimulus, biasing selection toward things like bright, flashing lights and loud, sudden noises. Top-down processes on the other hand are based on the internal goals of the individual, biasing selection toward, for example, the red and white hat worn by a friend that you’ve lost in a crowd. More recently, @awh2012top suggested that a third factor, selection history, is integrated with both top-down and bottom-up information in order to direct attention in a visual scene.

Selection history refers to an individual’s previous experience of encountering and responding to a stimulus in a given context, and evidence for its impact on attention has come from a range of observations. One such example of how selection history impacts on the deployment of attention is demonstrated by intertrial priming. In visual search tasks where target features vary from trial to trial, intertrial priming refers to the observation that participants respond significantly faster to the current target when it matches the features of the target from the preceding trial [@fecteau2007priming;@nakayama2004short;@maljkovic1994priming;@wolfe2003changing]. Notably, features associated with a previous trial’s target are primed even in cases where they contradict the current top-down goals of the participant [@maljkovic1994priming]. Similarly, associating a stimulus with reward has been shown to produce increased attentional capture by that stimulus long after the reward has stopped [@anderson2011value;@hickey2010reward;@hickey2013reward;@kiss2009reward]. Intertrial priming and reward association both demonstrate the critical role that selection history plays alongside bottom-up and top-down influences on attentional control.

The impact that selection history has on the allocation of attention has also been shown to persist even when participants are performing a different task. @feldmann2015you demonstrated this using a dual task paradigm in which participants performed either a learning task or a search task on each trial. During the learning task participants learned to categorise stimuli based on either colour or shape, while in the search task they searched for a shape singleton and responded to the rotated line that it contained. Their results showed that when colour singletons were present in the search displays, these distractors caused greater interference on the search task for participants who had performed colour categorization in the learning task. This implies that colour became more salient as a result of selection history, and follow-up experiments showed that these effects persist when the tasks are performed in separate blocks, and on separate days.

Additional insight into the effect of learning history on attention has been provided through the measurement of neural indices of attention processing recorded by EEG. One of the predominant components used to study attention is an enhanced negativity recorded at posterior electrode sites contralateral to an attended stimulus, occurring approximately 200ms after stimulus onset. Referred to as N2pc, this component is generally considered to reflect the deployment of spatially selective attention to the stimulus [@ansorge2011initial;@eimer2007attentional;@luck1994spatial;@luck1994electrophysiological], and has been used as an index of attentional capture by relevant stimuli [@kiss2008n2pc] and pop-out objects [@eimer2007attentional;@holguin2009n2pc]. In their dual task investigation into the effects of learning history on attention, @feldmann2015you showed that during search trials, participants that had performed colour categorisation in the learning task produced an N2pc to the colour distractor whereas participants who performed shape categorisation did not. These data support the suggestion that selection history results in the automatic allocation of attention to stimuli even when they are currently task irrelevant.

Recently, methodological developments have allowed for even more specific measures of attention processing using EEG. Efficient attentional orienting depends not only on efficient mechanisms for identifying and orienting to targets, but also the identification and suppression of possible distractors. Distinguishing between these processes using only behavioural measures has proven difficult, however, recent research has identified a set of lateralized event-related potentials that can provide dissociable measures of object selection and suppression. Central to the calculation of the N2pc is the subtraction of any neural activity that is represented equally in both hemispheres. @hickey2009electrophysiological took advantage of this fact in order to dissociate target and distracter processing. Participants in their task performed a visual search task in which both a target and distractor were present, but only one of these objects was lateralized on a given trial. When a target is lateralized and the distractor is on the midline, calculation of lateralized ERPs results in subtraction of all distractor activity and isolation of lateralized target processing. Similarly, when the distractor is lateralized, activity related to distractor processing can be isolated. Results using this approach have identified an early lateralized negativity indexing the attentional selection of a stimulus, and a later lateralized positivity reflecting attentional disengagement from a stimulus.

Specific measures of attentional selection and suppression have provided increased specificity of the role that selection history plays in the orienting of attention. In a follow-up experiment @feldmann2015you adapted their task in order to allow for the dissociation of target and distractor processing. Their results showed that for participants who categorized based on color in the learning task, the presentation of a colored distractor in the search task elicited an ND (a lateralised negativity to distractors) follow by a relatively large PD (a lateralised positivity to distractors). This implies that for these participants, the color distractor captured attention reflexively in the search task (reflected by ND) and therefore required increased subsequent suppression (reflected by increased PD). Participants who had learned to categorize based on shape however did not show this effect. The color distractor in this case elicited no ND during search trials, and a small PD indexing a lack of attentional capture and decreased distractor suppression respectively.

An open question remains as to whether increased top-down control can be used to attenuate, or eliminate the effects of selection history on attention. Previously, dual task investigations of the effect have attempted to enhance top-down control processes by providing cues to participants which inform them of which task they’re about to perform [@kadel2017selection]. While this allows participants to switch task sets in preparation for the upcoming trial, the effect of selection history on attention has remained suggesting that top-down control cannot be used to override the effects of selection history. However, recent work has suggested that these cues are insufficient for allowing participants to optimally engage top-down control before the trial begins. A novel approach to increasing top-down attentional control in dual tasks is the voluntary task-switching paradigm developed by @arrington2004cost. In this version of the task, participants are not cued as to what trial type will be performed next, but rather they are given the choice of which trial type they would like to perform next. Evidence suggests that the voluntary task switching paradigm allows for stronger proactive control over performance of each task [@arrington2005voluntary;kang2014electrophysiological].

In the present study, we adapted the design of @feldmann2015you to a voluntary task switching paradigm in order to investigate the relationship between top-down control and selection history. By allowing participants to determine whether they would perform search or learning on the next trial, participants would be able to proactively engage the task set for the upcoming trial and exercise greater top-down control. We also recorded EEG during their performance of the task and leveraged the procedure of @hickey2009electrophysiological to allow for the isolation of target and distractor activity. This approach provides specific measures of target selection and disengagement, as well as distractor selection and suppression during the task, and therefore provides a fine grained understanding of how increased top-down control interacts with selection history during attentional orienting. If increased top-down control is able to eliminate the effects of selection history then we would expect to see distractor costs in the search task to be similar regardless of whether participants were assigned to the shape or colour group in the learning task. We would als expect that group assignment would have no differential effects on the lateralised ERP components elicited by stimuli in the search task. On the other hand, if top-down control cannot be used to override selection history effects then the effect of learning group assignment on distractor costs and ERP component ampolitudes during search should remain.

# Methods

## Participants

27 participants with normal or corrected-to-normal vision (tested using an Oculus Binoptometer 3) participated in the task for either payment or course credit. All participants gave written and informed consent prior to the start of the experiment. Participants were randomly assigned to either the shape group (ages ranging form XXXX to XXXX, mean = XXXX, SD = XXXX) or the colour group (ages ranging form XXXX to XXXX, mean = XXXX, SD = XXXX). Each group had one left handed participant and all other participants were right handed. One participant did not reach suitable performance during the practice session and was therefore excluded from the experiment.

## Experimental procedure

Participants came in for two separate sessions and performed two different tasks within each session, a learning task and a search task. In session one, participants were familiarised with the two tasks by performing them in separate blocks. In session two, the full task began where participants chose at the start of each trial whether they would perform a learning or search trial. Participants were seated in a comfortable chair in a dimly lit room with their eyes 100cm away from the screen (LCD-TN Samsung Syncmaster 2233). An Erogodex DX1 repsonse pad was placed on their lap with 6 keys arranged so that participants could use the index and middle finger of each hand to respond to the task, while the thumb on each hand could be used to perform task selection between trials. Stimulus presentation and repsonse collection was controlled by E-Prime 2.0 and audio feedback was presented by two stereo speakers (Logitech
Z120 2.0) placed behind the screen.

This procedure followed the logic of Feldmann-Wustefeld (XXXX) where selection history is measured as the effect of the learning task on performance in the search task. The addition of voluntary task selection allowed for us to investigate the influence that top-down control may have on the role of selection history.

### Stimuli

All stimuli presented during the learn and search trials were presented on a dark grey background and subtended 2.3 degrees of visual angle. A fixation cross (0.6 degrees) was located in the centre of the screen throughout the experiment in order to help participants maintain central fixation. The physical luminance of the grey, green, blue, and red stimulus colours was balanced using a luminance meter (Konica Minolta LS-100).

### Learning trials

Learning trials began with a 500-XXXX ms fixation cross in the center of the screen. Eight stimuli were then presented simultaneously in a circular arrangement for 200 ms, six of these were unfilled grey circles, one was an unfilled coloured circle (either blue or green randomly selected on each trial), and one was an unfilled grey shape singleton (either pentagon or triangle selected randomly on each trial). Participants had two response keys for the learning task and after selecting one of these keys, they were given feedback informing them whether they had selected the correct response. At the beginning of the task, participants were not told the correct stimulus reponse pairing and instead had to learn which key was correct for a given display. For half of the participants (the colour group) the correct response was based on the colour singleton (eg. key 1 when blue was shown, key 2 when green was shown). For the other half of participants (the shape group) the correct response was based on the shape singleton (eg. key 1 when a pentagon was shown, key 2 when a triangle was shown). Participants had 2000ms to respond on each trial.

### Search trials

Search trials began with a 500-XXXX ms fixation cross in the center of the screen. Eight stimuli were then presented simultaneously in a circular arrangement for 200 ms, six of these were always unfilled grey circles, and one was the target, an unfilled grey diamond. The final stimulus was either another unfilled grey circle (in the target only condition) or an unfilled red circle (in the distractor present condition). Each of these stimuli contained a straight line of varying orientations and participants were required to indicate whether the line contained by the target diamond was oriented horizontally or vertically. Participants had 2000 ms to respond on each trial.

### Task selection

In session two, every trial began with a task selection screen where participants had to indicate using either their left or right thumbs, whether they would like to perform a learn or search trial. This screen stayed on until the participant response. Participants were asked to try to ensure that they distributed their choices evenly between the two options, and to try and make their choice random and unpredictable. Participants were required to perform 576 of each trial type and after every block of 32 trials, participants were shown a pictoral display (an exmaple is shown in figXXXX) indicating how many of each trial type was left for them to perform.

### EEG recording



### EEG processing

EEG data was processed using the EEGLAB toolbox in MATLAB. Epoched, baselined, HEOG and VEOG created and lowpass filtered 35Hz and trials contianing HEOG (+/- 35) and VEOG (+/-80) removed. Trials containing +/- 80mv in the channels of interest were also removed and the data was average referenced. Left hemisphere (PO3,PO7) and right hemisphere (PO4,PO8) pools were created.

# Results
```{r exclusion criteria}
minSwitchRate = 0.2
```


## Behavioral results
```{r loadBehavData}
groupInfo = read.csv(file="BehaviouralData.csv")
#Load all data
behavData = read.csv(file="Behaviour/CSL_Choice_behav.csv")
behavData <- select(behavData,-c(ExperimentName, Session, Clock.Information, DataFile.Basename, Display.RefreshRate, ExperimentVersion, RandomSeed, RuntimeCapabilities, RuntimeVersion, RuntimeVersionExpected, SessionDate, SessionStartDateTimeUtc, SessionTime, StudioVersion,BlockAccC, BlockAccL, BlockRTC, BlockRTL, Group, pos1, pos2, pos3, pos4, pos5, pos6, pos7, pos8, Response.DurationError, Response.OnsetDelay, Response.OnsetTime, Response2.DurationError, Response2.OnsetDelay, Response2.OnsetTime)
)
```

```{r , include=FALSE}

for (sub in unique(behavData$Subject)) {
  behavData$Group[behavData$Subject==sub] = groupInfo$Group[groupInfo$Subject==sub]
  behavData$switchRate[behavData$Subject==sub] = groupInfo$SwitchRate[groupInfo$Subject==sub]
  behavData$compSD[behavData$Subject==sub] = sd(filter(behavData,Subject ==sub, Procedure.Trial. == "TaskC")$CompSearch.RT)
  behavData$compMean[behavData$Subject==sub] = mean(filter(behavData,Subject ==sub, Procedure.Trial. == "TaskC")$CompSearch.RT)
  behavData$learnSD[behavData$Subject==sub] = sd(filter(behavData,Subject ==sub, Procedure.Trial. == "TaskL")$LearnSearch.RT)
  behavData$learnMean[behavData$Subject==sub] = mean(filter(behavData,Subject ==sub, Procedure.Trial. == "TaskL")$LearnSearch.RT)
  
  
}
behavData$compCutoff <- behavData$compMean + (behavData$compSD * 2.5)
behavData$learnCutoff <- behavData$learnMean + (behavData$learnSD * 2.5)
behavData <- behavData %>% 
  mutate(SwitchCount = ifelse(repswitch=="switch",1,0))
behavData$Trial <- behavData$Block
behavData$Block <- trunc(unique(behavData$Block)/32-0.00001)+1

#Subject group table
behavData %>% 
  group_by(Subject) %>%
  summarise(Group = mean(Group))
behavData = behavData %>% mutate(Group = ifelse(Group==1,"Colour","Shape"))
behavData$Group = as.factor(behavData$Group)

#Save switch rates for ERP
switchRates <- behavData %>% group_by(Subject) %>%summarise(SR = mean(switchRate))
```

```{r, echo = FALSE, include = FALSE}
autoCor <- data.frame(matrix(ncol = 3, nrow = 0))
colnames(autoCor) <- c("Cor", "Subject", "Group")

for (subj in unique(behavData$Subject)) {
sData <- behavData %>% filter(Subject == subj)
Cor <- acf(sData$SwitchCount,lag.max = 576,plot = TRUE)$acf
Cor = data.frame(Cor)
Cor$Subject = subj
Cor$Group = behavData$Group[behavData$Subject==subj][1]
autoCor <- rbind(autoCor,Cor[])
}

autoCor$Cor <- sqrt(autoCor$Cor^2)

autoCor %>%
  filter(Cor < 1) %>%
  group_by(Subject,Group) %>%
  summarise(Cor = mean(Cor))
t.test(autoCor$Cor[autoCor$Group=="Colour"],autoCor$Cor[autoCor$Group=="Shape"], paired = FALSE)
```

### Distractor cost

```{r behavStats}
colourBehav <- behavData %>%
  filter(Procedure.Trial. == "TaskC",switchRate>minSwitchRate, CompSearch.ACC==1, CompSearch.RT < compCutoff) %>%
  group_by(Subject, TrialType, Group) %>%
  summarise(RT = mean(CompSearch.RT)) %>%
  spread(TrialType, RT) %>%
  mutate(DistInt = TD-Tonly, GroupNum = as.integer(Group)) %>%
  filter(Group=="Colour")

shapeBehav <- behavData %>%
  filter(Procedure.Trial. == "TaskC",switchRate>minSwitchRate, CompSearch.ACC==1, CompSearch.RT < compCutoff) %>%
  group_by(Subject, TrialType, Group) %>%
  summarise(RT = mean(CompSearch.RT)) %>%
  spread(TrialType, RT) %>%
  mutate(DistInt = TD-Tonly, GroupNum = as.integer(Group)) %>%
  filter(Group=="Shape")
t.out = t.test(colourBehav$DistInt,shapeBehav$DistInt)
intEffectTTest = apa_print(t.out)
```

In order to test for the effect of selection history when top-down control was maximised, we evaluated the effect of group assignment in the categorisation on performance in the search task. First, we removed trials with incorrect responses and abnormally long reaction times (greater than 2.5 standard deviations above the mean, calculated separately for each participant). At this point, we calculated distractor cost by taking the difference in response times between the target only trials and the distractor present trials. An independent samples t-test comparing distractor interference between the colour-trained group and the shape-trained group showed that those trained to categorise colours were subject to greater interference by the colour distractor in the search task (`r intEffectTTest$full_result`). This is shown in figure\ \@ref(fig:DistIntViolin).

(ref:behavDistInt) Violin plot showing the response time cost caused by a colored distractor during visual search for both the shape and color trained groups. 

```{r DistIntViolin, fig.cap = "(ref:behavDistInt)"}
behavData %>%
  filter(Procedure.Trial. == "TaskC",switchRate>minSwitchRate, CompSearch.ACC==1, CompSearch.RT < compCutoff) %>%
  group_by(Subject, TrialType, Group) %>%
  summarise(RT = mean(CompSearch.RT)) %>%
  spread(TrialType, RT) %>%
  mutate(DistInt = TD-Tonly, GroupNum = as.integer(Group)) %>%
  ggplot( aes(x = GroupNum, y = DistInt, fill = Group)) +
  geom_flat_violin(aes(fill = Group),position = position_nudge(x = .1, y = 0), adjust = 1.5, trim = FALSE, alpha = .5, colour = NA) +
  geom_point(aes(x = GroupNum-0.15, y = DistInt, colour = Group),position = position_jitter(width = .05), size = 4, shape = 20) +
  geom_boxplot(aes(x = GroupNum, y = DistInt, fill = Group),outlier.shape = NA, alpha = .5, width = .1, colour = "black") +
  scale_color_manual(values=c("green4", "gray42")) +
  scale_fill_manual(values=c("green4", "gray42")) +
  labs(y = "Distractor Cost (ms)") +
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.background = element_blank(),
        axis.line = element_line(colour = "black"),
        axis.text.x = element_blank(),
        axis.title.x = element_blank(),
        axis.ticks = element_blank(),
        text= element_text(size=18)
        )
```


```{r, include = FALSE}
rm(behavData, colourBehav, GeomFlatViolin, GeomSplitViolin, groupInfo,intEffectTTest,shapeBehav,t.out, geom_flat_violin,geom_split_violin)
gc()
```

## ERP results

```{r organiseData}
dPath = 'CSL_Visuals/'
fPrefix = 'N2pc'

#Load group data
groupdata = read.csv(file="CSL_Visuals/SophiaGroupAssignment_provisional.csv")
groupdata = groupdata %>% mutate(Group = ifelse(Group == 1, "Colour", "Shape"))
groupdata$Reject = as.factor(groupdata$Reject)

#####
#Creates aggregate of all participant data (needs dPath and fPrefix)
eFilePattern = paste(fPrefix,"*_epochs.csv", sep="")
lFilePattern = paste(fPrefix,"*_LH.csv", sep="")
rFilePattern = paste(fPrefix,"*_RH.csv", sep="")
eFileList = list.files(dPath, pattern=glob2rx(eFilePattern))
lFileList = list.files(dPath, pattern=glob2rx(lFilePattern))
rFileList = list.files(dPath, pattern=glob2rx(rFilePattern))

#create variables using first dataset
epochInfo = read.csv(file = paste(dPath,eFileList[1], sep=""))
epochInfo$Subject = 1
epochInfo$Group = groupdata$Group[1]
epochInfo$Reject = groupdata$Reject[1]
epochInfo$switchRate = switchRates$SR[1]
lHemData = read.csv(file = paste(dPath,lFileList[1], sep=""), header = FALSE)
rHemData = read.csv(file = paste(dPath,rFileList[1], sep=""), header = FALSE)
#append the other datasets to the above variables
for (subj in 2:length(eFileList)) {
  curEpochInfo = read.csv(file = paste(dPath,eFileList[subj], sep=""))
  curEpochInfo$Subject = subj
  curEpochInfo$Group = groupdata$Group[subj]
  curEpochInfo$Reject = groupdata$Reject[subj]
  curEpochInfo$switchRate = switchRates$SR[subj]
  curLHemData = read.csv(file = paste(dPath,lFileList[subj], sep=""), header = FALSE)
  curRHemData = read.csv(file = paste(dPath,rFileList[subj], sep=""), header = FALSE)
  
  epochInfo = rbind(epochInfo, curEpochInfo)
  lHemData = rbind(lHemData, curLHemData)
  rHemData = rbind(rHemData, curRHemData)
}
#Tidy the variables, remove unnecessary and convert to factors
epochInfo$Subject = as.factor(epochInfo$Subject)
epochInfo$Group = as.factor(epochInfo$Group)
epochInfo$VarName8 = NULL
epochInfo$VarName9 = NULL
epochInfo$VarName10 = NULL
epochInfo$VarName11 = NULL

#clear stuff that I don't need
rm(curEpochInfo,curLHemData,curRHemData, fPrefix, eFileList, eFilePattern, lFileList, lFilePattern, rFileList, rFilePattern, subj, groupdata)
#####
#Permutation can be done at this stage using epochInfo$Hemifield = sample(epochInfo$Hemifield, replace=FALSE)
#combine all the data together into one long table
gathercols = colnames(lHemData)
lHemData$Hem = "Left"
rHemData$Hem = "Right"
scalpData = rbind(lHemData,rHemData)
origEpochInfo = rbind(epochInfo,epochInfo)

allData <- cbind(origEpochInfo, scalpData)
allData <- gather(allData, "sample", "voltage", gathercols, factor_key = TRUE)

#Tidy variable names etc. and create any necessary variables - could use unite
allData$sample <- as.integer(substring(allData$sample,2))
allData <- allData %>% mutate(Contra = ifelse(Hemifield==Hem, "Ipsilateral", "Contralateral"))
allData <- allData %>% mutate(Stimulus = as.factor(paste(LatStim," (",MidStim," mid)", sep = "")))
allData <- allData %>% mutate(Object = as.factor(paste(Group,LatStim, sep="")))
allData$Object <- recode(allData$Object, ShapePredictor = "Shape", ColourPredictor="Colour", ShapeNonPred = "Colour", ColourNonPred = "Shape")
allData$Stimulus <- recode(allData$Stimulus, "Target (None mid)" = "Target only", "Target (Distractor mid)"="Target", "Distractor (Target mid)" = "Distractor")

#clear stuff that I don't need
rm(origEpochInfo,scalpData)
#Change factor labels
allData$Object = factor(allData$Object, labels = c("ColourDistractor", "ColourNone", "Lat. Shape", "Lat. Colour", "ColourTarget", "ShapeDistractor", "ShapeNone", "ShapeTarget"))
allData$Object = factor(allData$Object, levels = c("Lat. Colour", "Lat. Shape", "ColourNone", "ShapeNone", "ColourTarget", "ShapeTarget", "ColourDistractor", "ShapeDistractor"))
allData$Group = factor(allData$Group, levels = c("Colour", "Shape"))
allData$TrialType = factor(allData$TrialType, levels = c("Switch", "Rep"))
allData$Stimulus = factor(allData$Stimulus, levels = c("Target only", "Target", "Distractor"))
```

```{r setParams}
baseline = 200
srateMultiplier = 1
plotWidth = 24
plotHeight = 9
fontSize = 12
winSize = 50


learnRej <- allData %>%
  filter(Event == "Learn", sample == 1, Contra == "Contralateral") %>%
  group_by(Subject) %>%
  summarise(Trials = sum(sample)) %>%
  mutate(learnReject = ifelse(Trials < 400,1,0))
searchRej <- allData %>%
  filter(Event == "Search", sample == 1, Contra == "Contralateral") %>%
  group_by(Subject) %>%
  summarise(Trials = sum(sample)) %>%
  mutate(searchReject = ifelse(Trials < 500,1,0))
#mutate(allData, learnRej = NaN, searchRej = NaN)
for (i in unique(allData$Subject)) {
  allData$learnRej[allData$Subject == i] = learnRej$learnReject[learnRej$Subject==i]
  allData$searchRej[allData$Subject == i] = searchRej$searchReject[searchRej$Subject==i]
}
```

### Categorization task

```{r}
grandTarget <- allData %>%
  filter( Event == "Learn" & LatStim == "Predictor" & searchRej == 0) %>%
  mutate(sample = sample*srateMultiplier-baseline) %>%
  filter(sample > 200) %>%
  group_by(sample,Contra) %>%
  summarise(mean = mean(voltage)) %>%
  spread(Contra, mean) %>% 
  mutate(diff = Contralateral - Ipsilateral)
NtStart = grandTarget$sample[grandTarget$diff == min(grandTarget$diff)]-winSize/2
NtEnd = grandTarget$sample[grandTarget$diff == min(grandTarget$diff)]+winSize/2
grandDist <- allData %>%
  filter( Event == "Learn" & LatStim == "NonPred" & searchRej == 0) %>%
  mutate(sample = sample*srateMultiplier-baseline) %>%
  filter(sample > 200) %>%
  group_by(sample,Contra) %>%
  summarise(mean = mean(voltage)) %>%
  spread(Contra, mean) %>% 
  mutate(diff = Contralateral - Ipsilateral)
PdStart = grandDist$sample[grandDist$diff == max(grandDist$diff)]-winSize/2
PdEnd = grandDist$sample[grandDist$diff == max(grandDist$diff)]+winSize/2
```

```{r learnGrand, include = FALSE}
allData %>%
  filter(Event == "Learn", learnRej == 0) %>%
  mutate(sample = sample*srateMultiplier-baseline) %>%
  group_by(LatStim,sample,Contra) %>%
  summarise(mean = mean(voltage)) %>%
  spread(Contra, mean) %>% 
  mutate(diff = Contralateral - Ipsilateral) %>%
  ggplot(., aes(sample,diff)) +
    geom_rect(aes(xmin = NtStart, xmax = NtEnd, ymin = -Inf, ymax = 0), fill = "lemonchiffon") +
    geom_rect(aes(xmin = PdStart, xmax = PdEnd, ymin = 0, ymax = Inf), fill = "lemonchiffon") +
    geom_line(aes(colour = LatStim),size=1) +
    scale_color_manual(values=c("green4", "gray42"))+
    scale_x_continuous(name ="Latency (ms)", expand = c(0, 0)) +
    scale_y_reverse(name =expression(paste("Amplitude (",mu,"v)")), expand = c(0, 0)) +
    geom_vline(xintercept = 0,linetype = "dashed" ) +
    geom_hline(yintercept = 0,linetype = "dashed") +
    theme_apa() +
    theme(panel.spacing.y = unit(3, "lines"), text= element_text(size=fontSize),
          axis.text.x = element_text(size = fontSize*0.93),
          axis.text.y = element_text(size = fontSize*0.93),
          legend.title = element_text( size = fontSize*1.1),
          legend.text = element_text( size = fontSize*0.93),
          legend.position = "bottom"
          )
```

```{r learnStats, echo=FALSE, include = FALSE}
learnNtShape <- allData %>%
  mutate(sample = sample*srateMultiplier-baseline) %>%
  filter(Event == "Learn" & learnRej == 0 & sample>NtStart & sample < NtEnd & Object == "Lat. Shape") %>%
  group_by(Object,Subject,Contra,Group) %>%
  summarise(mV = mean(voltage))
learn.NtShape.aov <- aov_ez(
  data = learnNtShape,
  dv = "mV",
  id = "Subject", 
  within = c("Contra"),
  between = "Group"
)
learn.NtShape.results <- apa_print(learn.NtShape.aov)
#Followup
learn.NtShape.fup <- apa_print.emmGrid(pairs(emmeans(learn.NtShape.aov, ~Contra|Group)))
diffDirect <- learnNtShape %>%
  spread(Contra,mV) %>%
  mutate(difference = Contralateral-Ipsilateral)
t.test(diffDirect$difference[diffDirect$Group == "Shape"], diffDirect$difference[diffDirect$Group == "Colour"],paired = FALSE)

learnNtCol <- allData %>%
  mutate(sample = sample*srateMultiplier-baseline) %>%
  filter(Event == "Learn" & learnRej == 0 & sample>NtStart & sample < NtEnd & Object == "Lat. Colour") %>%
  group_by(Object,Subject,Contra,Group) %>%
  summarise(mV = mean(voltage))
learn.NtCol.aov <- aov_ez(
  data = learnNtCol,
  dv = "mV",
  id = "Subject", 
  within = c("Contra"),
  between = "Group"
)
learn.NtCol.results <- apa_print(learn.NtCol.aov)
#Followup
learn.NtCol.fup <- apa_print.emmGrid(pairs(emmeans(learn.NtCol.aov, ~Contra|Group)))
diffDirect <- learnNtCol %>%
  spread(Contra,mV) %>%
  mutate(difference = Contralateral-Ipsilateral)
t.test(diffDirect$difference[diffDirect$Group == "Shape"], diffDirect$difference[diffDirect$Group == "Colour"],paired = FALSE)

learnPdShape <- allData %>%
  mutate(sample = sample*4-baseline) %>%
  filter(Event == "Learn" & learnRej == 0 & sample>PdStart & sample < PdEnd & Object == "Lat. Shape") %>%
  group_by(Object,Subject,Contra,Group) %>%
  summarise(mV = mean(voltage))
learn.PdShape.aov <- aov_ez(
  data = learnPdShape,
  dv = "mV",
  id = "Subject", 
  within = c("Contra"),
  between = "Group"
)
learn.PdShape.results <- apa_print(learn.PdShape.aov)

learnPdCol <- allData %>%
  mutate(sample = sample*srateMultiplier-baseline) %>%
  filter(Event == "Learn" & learnRej == 0 & sample>PdStart & sample < PdEnd & Object == "Lat. Colour") %>%
  group_by(Object,Subject,Contra,Group) %>%
  summarise(mV = mean(voltage))
learn.PdCol.aov <- aov_ez(
  data = learnPdCol,
  dv = "mV",
  id = "Subject", 
  within = c("Contra"),
  between = "Group"
)
learn.PdCol.results <- apa_print(learn.PdCol.aov)
```

In the categorisation task, our ERP analyses focused on the lateralised response to each object (either the shape singleton or the colour singleton). For each ERP there were two time windows of interest, the Nt time window (`r sprintf("%i to %ims", NtStart, NtEnd)`) and the Pd time window (`r sprintf("%i to %ims", PdStart, PdEnd)`). See figure\ \@ref(fig:makeLearnPlots).

#### Colour singleton response

When focussing on the lateralised response to a colour singleton we see no significant main effects of either group (`r learn.NtCol.results$full$Group`) or hemisphere (`r learn.NtCol.results$full$Contra`), however we do see a significant interaction between group and hemisphere (`r learn.NtCol.results$full$Group_Contra`). Follow-up comparisons reveal that for participants in the colour group, a lateralised colour singleton elicits a significant NT component (`r learn.NtCol.fup$full_result$Contralateral_Ipsilateral_Colour`), whereas for participants in the shape group a significant lateralised positivity is elicited by the colour singleton (`r learn.NtCol.fup$full_result$Contralateral_Ipsilateral_Shape`). When evaluating the PD time range, we observe no main effects of group(`r learn.PdCol.results$full$Group`) or hemisphere (`r learn.PdCol.results$full$Contra`) on voltage, and no interaction between group and hemisphere (`r learn.PdCol.results$full$Group_Contra`).

#### Shape singleton response

When focussing on the lateralised response to a shape singleton we again see no significant main effects of either group (`r learn.NtShape.results$full$Group`) or hemisphere (`r learn.NtShape.results$full$Contra`), however we do see a significant interaction between group and hemisphere (`r learn.NtShape.results$full$Group_Contra`). Follow-up comparisons reveal that for participants in the shape group, a lateralised shape singleton elicits a significant NT component (`r learn.NtShape.fup$full_result$Contralateral_Ipsilateral_Shape`), whereas for participants in the colour group a significant lateralised positivity is elicited by the shape singleton (`r learn.NtShape.fup$full_result$Contralateral_Ipsilateral_Colour`).  When evaluating the PD time range, we observe no main effects of group(`r learn.PdShape.results$full$Group`) or hemisphere (`r learn.PdShape.results$full$Contra`) on voltage, and no interaction between group and hemisphere (`r learn.PdShape.results$full$Group_Contra`).

(ref:learnERPCap) Subtractracted ERPs showing the lateralized response to the shape singleton (top) and color singleton (bottom) for each group in the categorization task. Example displays are shown for each ERP.

```{r makeLearnPlots, fig.cap="(ref:learnERPCap)"}
imgCol <- readPNG("learnCol.png")
imgShape <- readPNG("learnShape.png")
#Subtracted
allData %>%
  filter(Event == "Learn", learnRej == 0) %>%
  mutate(sample = sample*srateMultiplier-baseline) %>%
  group_by(Object,sample,Contra,Group) %>%
  summarise(mean = mean(voltage)) %>%
  spread(Contra, mean) %>% 
  mutate(diff = Contralateral - Ipsilateral) %>%
  ggplot(., aes(sample,diff)) +
    geom_rect(aes(xmin = NtStart, xmax = NtEnd, ymin = -Inf, ymax = 0), fill = "lemonchiffon") +
    geom_rect(aes(xmin = PdStart, xmax = PdEnd, ymin = 0, ymax = Inf), fill = "lemonchiffon") +
    geom_line(aes(colour = Group),size=1) +
    scale_color_manual(values=c("green4", "gray42"))+
    scale_x_continuous(name ="Latency (ms)", expand = c(0, 0)) +
    scale_y_reverse(name =expression(paste("Amplitude (",mu,"v)")), expand = c(0, 0)) +
    coord_cartesian(clip = 'off') +
    geom_vline(xintercept = 0,linetype = "dashed" )+
    geom_hline(yintercept = 0,linetype = "dashed") +
    annotation_custom2(rasterGrob(imgCol, interpolate=TRUE), 
                       xmin=-45, 
                       xmax=45, 
                       ymin=0.25, 
                       ymax=3, 
                       data=. %>% filter(Object  == "Lat. Colour"))+
    annotation_custom2(rasterGrob(imgShape, interpolate=TRUE), 
                       xmin=-45, 
                       xmax=45, 
                       ymin=0.25, 
                       ymax=3, 
                       data=. %>% filter(Object  == "Lat. Shape"))+
    facet_grid(Object~.) +
    theme_apa() +
    theme(panel.spacing.y = unit(3, "lines"), text= element_text(size=fontSize),
          axis.text.x = element_text(size = fontSize*0.93),
          axis.text.y = element_text(size = fontSize*0.93),
          legend.title = element_text( size = fontSize*1.1),
          legend.text = element_text( size = fontSize*0.93),
          legend.position = "bottom",
          plot.margin = unit(c(2,2,0,2),"cm")
          )
ggsave("LearnSubtracted.pdf", dpi = 300, width = 30, height = 20, units = c("cm"))
```



### Search task

```{r}
grandTarget <- allData %>%
  filter( Event == "Search" & LatStim == "Target" & searchRej == 0) %>%
  mutate(sample = sample*srateMultiplier-baseline) %>%
  filter(sample > 200) %>%
  group_by(sample,Contra) %>%
  summarise(mean = mean(voltage)) %>%
  spread(Contra, mean) %>% 
  mutate(diff = Contralateral - Ipsilateral)
NtStart = grandTarget$sample[grandTarget$diff == min(grandTarget$diff)]-winSize/2
NtEnd = grandTarget$sample[grandTarget$diff == min(grandTarget$diff)]+winSize/2
grandDist <- allData %>%
  filter( Event == "Search" & LatStim == "Distractor" & searchRej == 0) %>%
  mutate(sample = sample*srateMultiplier-baseline) %>%
  filter(sample > 200) %>%
  group_by(sample,Contra) %>%
  summarise(mean = mean(voltage)) %>%
  spread(Contra, mean) %>% 
  mutate(diff = Contralateral - Ipsilateral)
PdStart = grandDist$sample[grandDist$diff == max(grandDist$diff)]-winSize/2
PdEnd = grandDist$sample[grandDist$diff == max(grandDist$diff)]+winSize/2
```

```{r searchGrand, include = FALSE}
allData %>%
  filter( Event == "Search" & LatStim != "None" & searchRej == 0) %>%
  mutate(sample = sample*srateMultiplier-baseline) %>%
  group_by(LatStim,sample,Contra) %>%
  summarise(mean = mean(voltage)) %>%
  spread(Contra, mean) %>% 
  mutate(diff = Contralateral - Ipsilateral) %>%
  ggplot(., aes(sample,diff)) +
    geom_rect(aes(xmin = NtStart, xmax = NtEnd, ymin = -Inf, ymax = 0), fill = "lemonchiffon") +
    geom_rect(aes(xmin = PdStart, xmax = PdEnd, ymin = 0, ymax = Inf), fill = "lemonchiffon") +
    geom_line(aes(colour = LatStim),size=1) +
    #scale_color_manual(values=c("green4", "gray42"))+
    scale_x_continuous(name ="Latency (ms)", expand = c(0, 0)) +
    scale_y_reverse(name =expression(paste("Amplitude (",mu,"v)")), expand = c(0, 0)) +
    geom_vline(xintercept = 0,linetype = "dashed" ) +
    geom_hline(yintercept = 0,linetype = "dashed") +
    theme_apa() +
    theme(panel.spacing.y = unit(3, "lines"), text= element_text(size=fontSize),
          axis.text.x = element_text(size = fontSize*0.93),
          axis.text.y = element_text(size = fontSize*0.93),
          legend.title = element_text( size = fontSize*1.1),
          legend.text = element_text( size = fontSize*0.93),
          legend.position = "bottom"
          )
```

```{r searchStatsBasic, echo=FALSE}
searchNtTO <- allData %>%
  mutate(sample = sample*srateMultiplier-baseline) %>%
  filter(Event == "Search" & LatStim != "None" & searchRej == 0 & sample>NtStart & sample < NtEnd & Stimulus == "Target only", switchRate>minSwitchRate) %>%
  group_by(Stimulus,Subject,Contra,Group) %>%
  summarise(mV = mean(voltage)) 
search.NtTO.aov <- aov_ez(
  data = searchNtTO,
  dv = "mV",
  id = "Subject", 
  within = c("Contra"),
  between = "Group"
)
search.NtTO.results <- apa_print(search.NtTO.aov)
search.NtTO.fup <- apa_print.emmGrid(pairs(emmeans(search.NtTO.aov, ~Contra|Group)))

searchNtTD <- allData %>%
  mutate(sample = sample*srateMultiplier-baseline) %>%
  filter(Event == "Search" & LatStim != "None" & searchRej == 0 & sample>NtStart & sample < NtEnd & Stimulus == "Target", switchRate>minSwitchRate) %>%
  group_by(Stimulus,Subject,Contra,Group) %>%
  summarise(mV = mean(voltage))
search.NtTD.aov <- aov_ez(
  data = searchNtTD,
  dv = "mV",
  id = "Subject", 
  within = c("Contra"),
  between = "Group"
)
search.NtTD.results <- apa_print(search.NtTD.aov)
search.NtTD.fup <- apa_print.emmGrid(pairs(emmeans(search.NtTD.aov, ~Contra|Group)))
diffDirect <- searchNtTD %>%
  spread(Contra,mV) %>%
  mutate(difference = Contralateral-Ipsilateral)
NtTDdiff <- apa_print(t.test(diffDirect$Contralateral[diffDirect$Group == "Shape"], diffDirect$Ipsilateral[diffDirect$Group == "Shape"],paired = TRUE))

searchNtDT <- allData %>%
  mutate(sample = sample*srateMultiplier-baseline) %>%
  filter(Event == "Search" & LatStim != "None" & searchRej == 0 & sample>NtStart & sample < NtEnd & Stimulus == "Distractor", switchRate>minSwitchRate) %>%
  group_by(Stimulus,Subject,Contra,Group) %>%
  summarise(mV = mean(voltage))
search.NtDT.aov <- aov_ez(
  data = searchNtDT,
  dv = "mV",
  id = "Subject", 
  within = c("Contra"),
  between = "Group"
)
search.NtDT.results <- apa_print(search.NtDT.aov)
search.NtDT.fup <- apa_print.emmGrid(pairs(emmeans(search.NtDT.aov, ~Contra|Group)))

searchPdDT <- allData %>%
  mutate(sample = sample*srateMultiplier-baseline) %>%
  filter( Event == "Search" & LatStim != "None" & searchRej == 0 & sample>PdStart & sample < PdEnd & Stimulus == "Distractor", switchRate>minSwitchRate) %>%
  group_by(Stimulus,Subject,Contra,Group) %>%
  summarise(mV = mean(voltage))
search.PdDT.aov <- aov_ez(
  data = searchPdDT,
  dv = "mV",
  id = "Subject", 
  within = c("Contra"),
  between = "Group"
)
search.PdDT.results <- apa_print(search.PdDT.aov)
search.PdDT.fup <- apa_print.emmGrid(pairs(emmeans(search.PdDT.aov, ~Contra|Group)))
diffDirect <- searchPdDT %>%
  spread(Contra,mV) %>%
  mutate(difference = Contralateral-Ipsilateral)
PdDTdiff <- apa_print(t.test(diffDirect$difference[diffDirect$Group == "Colour"], diffDirect$difference[diffDirect$Group == "Shape"],paired = FALSE))

```

Next we focused on the lateralised response to stimuli in the search displays as a function of group assignment. Evidence for the effect of selection history would again come from the interaction between group and lateralised ERP activity.

#### Target response - Distractor absent trials

In the target only displays there was a significant main effect of hemisphere where the contralateral response is more negative than the ipsilateral response (`r search.NtTO.results$full$Contra`), but no siginificant main effect of group (`r search.NtTO.results$full$Group`), and no interaction between group and hemisphere (`r search.NtTO.results$full$Group_Contra`).

#### Target response - Distractor present trials

Results for the lateralised target in the presence of a distractor showed no significant main effect of group (`r search.NtTD.results$full$Group`), however there was a significant main effect of hemisphere (`r search.NtTD.results$full$Contra`), as well as a significant interaction between group and hemisphere (`r search.NtTD.results$full$Group_Contra`). Follow-up comparisons reveal that a significant NT was elicited for participants in both the colour (`r search.NtTD.fup$full_result$Contralateral_Ipsilateral_Colour`) and shape group (`r search.NtTD.fup$full_result$Contralateral_Ipsilateral_Colour`). When NT amplitude is compared directly with an independent samples t test, the results show that the NT is significantly larger for the shape group than the colour group (`r NtTDdiff$full_result`).

#### Distractor response

Results for the lateralised distractor showed no significant main effect of group (`r search.PdDT.results$full$Group`), however there was a significant main effect of hemisphere (`r search.PdDT.results$full$Contra`), as well as a significant interaction between group and hemisphere (`r search.PdDT.results$full$Group_Contra`). Follow-up comparisons reveal that a significant Pd was elicited for participants in the colour group (`r search.PdDT.fup$full_result$Contralateral_Ipsilateral_Colour`), however there was no significant difference between the contralateral and ipsilateral electrodes for the shape group (`r search.PdDT.fup$full_result$Contralateral_Ipsilateral_Shape`). When Pd amplitude is compared directly with an independent samples t test, the results show that the Pd is significantly larger for the colour group than the shape group (`r PdDTdiff$full_result`).

(ref:searchERPCap) Subtractracted ERPs showing the lateralized response to a target in the absence of distractors (top, the target in the presence of a distractor (middle), and the distractor (bottom) for each group in the search task. Example displays are shown for each ERP.

```{r makeSearchPlots, fig.cap="(ref:searchERPCap)", fig.height = 5.25,  fig.align = "center"}

imgTO = readPNG("searchTO.png")
imgTD = readPNG("searchTD.png")
imgDT = readPNG("searchDT.png")
allData %>%
  filter( Event == "Search" & LatStim != "None" & searchRej == 0) %>%
  mutate(sample = sample*srateMultiplier-baseline) %>%
  group_by(Stimulus,sample,Contra,Group) %>%
  summarise(mean = mean(voltage)) %>%
  spread(Contra, mean) %>% 
  mutate(diff = Contralateral - Ipsilateral) %>%
  ggplot(., aes(sample,diff)) +
    geom_rect(aes(xmin = NtStart, xmax = NtEnd, ymin = -Inf, ymax = 0), fill = "lemonchiffon") +
    geom_rect(data = . %>% filter(Stimulus  == "Distractor"),aes(xmin = PdStart, xmax = PdEnd, ymin = 0, ymax = Inf), fill = "lemonchiffon") +
    geom_line(aes(colour = Group),size=1) +
    scale_color_manual(values=c("green4", "gray42"))+
    #scale_colour_brewer(palette = "Set1") +
    scale_x_continuous(name ="Latency (ms)", expand = c(0, 0)) +
    scale_y_reverse(name =expression(paste("Amplitude (",mu,"v)")), expand = c(0, 0)) +
    coord_cartesian(clip = 'off') +
    geom_vline(xintercept = 0,linetype = "dashed" )+
    geom_hline(yintercept = 0,linetype = "dashed") +
    annotation_custom2(rasterGrob(imgTO, interpolate=TRUE), 
                       xmin=-45, 
                       xmax=45, 
                       ymin=0.5, 
                       ymax=3.2, 
                       data=. %>% filter(Stimulus  == "Target only"))+
    annotation_custom2(rasterGrob(imgTD, interpolate=TRUE), 
                       xmin=-45, 
                       xmax=45, 
                       ymin=0.5, 
                       ymax=3.2, 
                       data=. %>% filter(Stimulus  == "Target"))+
    annotation_custom2(rasterGrob(imgDT, interpolate=TRUE), 
                       xmin=-45, 
                       xmax=45, 
                       ymin=0.5, 
                       ymax=3.2, 
                       data=. %>% filter(Stimulus  == "Distractor"))+
    facet_grid(Stimulus~.) +
    theme_apa() +
    theme(panel.spacing.y = unit(3, "lines"), text= element_text(size=fontSize),
          axis.text.x = element_text(size = fontSize*0.93),
          axis.text.y = element_text(size = fontSize*0.93),
          legend.title = element_text( size = fontSize*1.1),
          legend.text = element_text( size = fontSize*0.93),
          legend.position = "bottom",
          plot.margin = unit(c(2,2,0,2),"cm")
          )
ggsave("SearchSubtracted.pdf", dpi = 300, width = 30, height = 40, units = c("cm"))
```

# Discussion

Previous research has established that an individual's learning history biases their attention during visual search, even when that learning history is task irrelevant and impairs search performance. In this study, we aimed to test whether the effects of learning history on attention guidance can be eliminated in situations where top-down control is maximised. To this end, we used a voluntary task selection design which allowed participants to decide which task they would like to perform on each trial. The results showed that learning history continues to bias attention during visual search leading to impaired target selection and distractor suppression. These effects are reflected both in response times as increased distractor costs, and in lateralised ERP components as simultaneous attenuation of the NT component and increase of the PD component.

Specifically, if participants learn to make categorisation judgements based on differentiating between two colours and subsequently search for a shape target while a coloured distractor is present, the NT component elicited by the shape target is attenuated and the PD elicited by the colour distractor is increased.

Learning history acts implicitly

# References
